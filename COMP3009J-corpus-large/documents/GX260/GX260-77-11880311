NEURAL NETWORKS BRIDGE CLEAN AIR ACT GAPS Making strides in previously untapped areas as environmental restrictions tighten, computer software is claiming an increasingly dominant role in power plant operations that can help utilities and industrial sources ensure emissions compliance.
And in some cases, artificial intelligence can heighten the effectiveness of clean coal technologies without inflating costs, rewarding coal-burning utilities that use clean coal technology-style equipment while potentially widening the market for clean coal systems overall.
P ETC , during the past five years, has pursued an aggressive, $2 million-plus, research campaign that focuses on developing simple ways to monitor complex tasks and capitalizing on the predictive capabilities of artificial intelligence software while enhancing them.
Both applications can be used in the coal arena, which has not benefitted from software programs now available for oil and gas plants.
In some states--Texas, for example, where natural gas usage is high--neural network software is an `
Commercial software packages are not sold on the market for coal because of its complex chemical properties.
Yet, there are almost as many ways to use artificial intelligence systems to upgrade efficiency in coal plants as there are coal characteristics.
Experiments here confirm that artificial intelligence systems can predict coal ash deposition and gauge how fuel switching, load changes, and retrofits effect NOX emissions.
On a pilot scale, PETC researchers are testing artificial intelligence systems' ability to estimate ash composition and thickness.
These uses certainly differ from today's commercial functions, which primarily center on coal preparation activities such as grinding coal, and utility plant maintenance duties, which include detecting problems with bearings.
While these cost-cutting features are important in a competitive field, they do not illustrate computer systems' abilities to maximize power plant efficiency or limit air emissions within federally mandated guidelines.
PETC personnel attempt to change that by expanding the best artificial intelligence systems' predictive aspects, thereby facilitating their evolution into an advisory role, a direction the industry expects computers to follow, says Ekmann.
The potential benefits are remarkable.
"Focusing on the right settings is easier than trial and error," he notes.
"With the costs of technologies rising, artificial intelligence offers an economically effective way for utilities to monitor emissions in conjunction with clean coal technologies.
It's a way of bridging the gap between basic capability and useful applications.
Artificial intelligence takes on problems that
Winter 1996 PETC Review
cannot be solved by other means.
" The progression is the next, natural step in software technology that will ultimately save power plant managers time and money while they satisfy Clean Air Act provisions, the most important environmental regulations affected from computer-generated predictions.
Next, they looked at utility-scale data.
Coal properties, boiler design features and boiler operating conditions were used to determine the frequency, thickness and nature of troublesome deposits.
Utility companies interested in switching fuel sources could use this network to screen various coals.
NOX Predictions More Accurate Another example of neural networks' predictive capabilities was successfully tested last year as part of a cooperative research and development agreement between PETC and the Electric Power Research Institute (EPRI), The two organizations created a NOX algorithm to judge the effects fuel switching, retrofits, and load changes would have on NO X emissions.
Estimates were within 60 ppm of measured NO X values, more precise than any other known predictive system.
(By contract, multiple linear regression, a statistical technique traditionally used to project emissions, brought accuracy within 175 ppm.)
Data from 36 units, representing more than 380 different operating conditions, were compiled into appropriate inputs programmed into a neural network incorporating the algorithm.
Predictive capabilities are enhanced, notes Ekmann, when NOX data improves specifically and broader operating parameters are used.
Further exploring a neural network's predictive aspects, PETC scientists found that networks outperformed multiple linear regressions in more than 120 data sets relating to slagging and fouling.
Although Battelle Columbus Laboratories, under an EPRI contract, provided varied raw data on several boiler types, its data were derived from only 45 plants.
Surveys from a few hundred more plants would be needed before reliable conclusions can be reached, explains Dave Wildman, heading artificial intelligence research at PETC.
"Analysts still need a better understanding of the interactions of the mineral constituents" before neural networks can be used to their fullest capacity in this application.
Recognized for his efforts in the field, Wildman was asked to write a chapter on the role artificial intelligence systems play in power systems for an encyclopedia that is to be published in July 1996.
The Encyclopedia of Desalination and Water Resources is designed to serve as a manual for water, energy, and global food security.
Lowering NOX Emissions by Upgrading SNCR Of the three areas that comprise artificial intelligence --neural networks, expert systems, and fuzzy logic-neural networks are best suited to be advisors, advanced systems that make recommendations based on various types of data (see Figure 1).
These recommendations, which change whenever a power plant's operations change, suggest how auxiliary plant equipment or technologies can be optimized.
Figure 1.
The three basic categories of artificial intelligence (Al) systems
For instance, PETC researchers used data from a Public Utility Service of Colorado coal plant to and knowledgebase. suggest how Selective Non-Catalytic Reduction When developing an (SNCR), a temperature-sensitive system showAl system for a specific cased through DOE's Clean Coal Technology purpose, a combination Program, could be optimized.
SNCR lowers of these systems, or a nitrogen oxides (NOX) emissions by injecting a hybrid system, may be employed as each has reagent such as ammonia or urea into the gas its strengths.
stream without a catalyst.
For this technology to Source: Bari Kosko, Neural operate at its best, the injection location of reNetworks and Fuzzy Systems, agent in the gas stream has to change whenever c 1992 Prentice-Hall.
Reprinted by permission.
load and temperatures fluctuate.
In a computer exercise, neural netFRAMEWORK works were able to Numerical select the right numSymbolic ber of injectors and Structured or the appropriate setRule-Like tings whenever temKnowledge peratures varied.
Such Unstructured or an accurate system Pattern Recognition would greatly benefit Knowledge the coal industry.
as they relate to structure
10
PETC Review Winter 1996
Neural Networks Surpass Other Systems the evolution of artificial intelligence systems, neural networks surpass their older cousins, expert systems and fuzzy logic.
The least specific type of artificial intelligence software, fuzzy logic is a type of expert system equipped with a set of approximate rules used whenever "close enough is good enough, " notes Ekmann.
Elevators and camera autofocusing systems are primary users of fuzzy logic systems.
Fuzzy logic stops an elevator at a floor when it is within a certain range, not at a specific, definite point.
Expert systems, on the other hand, "learn" by following a set of pre-established rules written in codes or computer language (see Figure 2).
Expert systems are assumed to understand the relationship between input and output information based on detailed knowledge of a specific process.
In
cost of the impact coal quality has on boiler performance, maintenance, operating costs, and emissions (PETC Review, Fall 1991) (see Figure 3a and b].
The beta version of the system has been tested by EPRI, CQ Inc., and three power utilities.
These test results have been incorporated into the expert system's set of rules and additional testing is underway involving other power companies.
A commercial version of the software is available through CQ, Inc.
Winter 1996 PETC Review
11
Figure 4.
Diagram of the structural relationship shared by biological and artificial neural networks.
The human brain contains approximately 10 11 o r 100 billion neurons.
At present, artificial neural systems may contain a network in the millions of neurons.
(Data source Thompson, 1985)
Neural networks are the latest type of artificial intelligence to enter the power plant industry.
Computational devices that use organized principles of biological nervous systems, neural networks do not assume relationships.
Instead, they determine relationships by analyzing data, learning much the way humans do, by example and repetition.
When it assigns an incorrect output with a given input, the network corrects itself by changing the weight matrices.
While it can take several days or weeks to complete this learning curve-- depending on the complexity of the problem-- neural networks outperform any other current approach to recognizing patterns.
Modeled after the human brain, made up of interconnected neurons that contain a limited amount of information, neural networks are constructed of simple data-processing units with limited capabilities (see Figure 4).
When connected together, they form the highest artificial intelligence system known, capable of estimating the lifespan of mechanical parts, diagnosing malfunctions in automobiles, and recognizing human speech.
Most importantly, they provide valuable information that cannot be obtained any other way.
can reposition itself to an "optimum" location in response to changes in the mixing zone of a gas stream of a coal plant.
When temperature fluctuates or flow rates differ from the normal pattern, the neural network determines where the probe should be.
Probes are used to pinpoint where a reagent can be sprayed or identify the best place to get a representative sample of emissions in a gas stream.
This particular exercise also shows that neural networks can work in conjunction with expert systems.
In this application, an expert system alerts a neural network to mixing zone changes and repositions the probe based on information from the network's servo-motors.
For the procedure to succeed, data gathering and preparation are crucial because they provide a point of reference from which the network can "learn" (see Figure 5).
In the PETC "smart probe" experiment, the mixing zone of two concurrent air streams was analyzed.
The optimum location was defined as the area in the mixing zone of minimum temperature variation.
The goal was to maintain the probe at the optimum location as the temperature profile varied by changing air stream temperature and flow rate.
Data gathering consisted of determining the mixing zone temperature profile for 37 different air stream temperature and flow rate combinations.
Thermocouples were placed throughout the mixing zone.
Data preparation consisted of constructing the temperature profile from the thermocouple data and determining the location of minimum temperature variation for each temperature profile.
Data were provided from tests that shifted air-stream temperatures between 100Â°F (38oC) and 160Â°F (71 oC) and varied stream flow rates between 10 standard liter per minute (SLPM) and 35 SLPM.
End Processes
Data Gathering Key to Learning Curve Neural networks highlight their value as process controllers in another PETC experiment.
The center developed a "smart probe, " which
8iological Neural Network
Dendrite: receives message
Transmitting Neuron
transfer connector
Neuron
Artificial Neural Network Processing Unit Connector Processing Unit
The neural network was trained to predict the coordinates of the minimum temperature variation in the mixing zone based on air stream temperatures and flow rates.
An expert system was developed to watch for changes in air stream flow rates and temperatures by monitoring the units's data PETC Review Winter 1996
12
acquisition files.
When a change occurred, the expert system passed the air stream conditions to the neural network, which determined the new probe position.
After receiving the new coordinates from the neural network, the expert system repositioned the probe by calling servo-motors.
The time required to recognize a change had occurred, determine the new location, and reposition the probe was less than 30 seconds.
I
Future Work Focuses on Emissions Predictions ecause a neural network's predictive uses are so important in helping utilities meet federally mandated emissions limits, PETC would like to focus on creating an environmental technology in which neural networks simulate emissions to monitor SO2, NOX and carbon monoxide.
Competing in EPA's multi-million-dollar Environmental Technology Initiative, the center and Pavilion Technologies Inc., a software manufacturer, submitted a proposal in which a computer program tailored for oil and gas plants would be modified so that coal's emissions can be predicted.
In the proposal, PETC would test the program on a 55,000-pounds-per-hour steam boiler the Bureau of Mines operates for heating buildings and experimental purposes.
One of 45 projects proposed by PETC in the Environmental Initiative, the project was not awarded funding, although four others were.
Of those, two have already received funding from EPA, which chose and financed in part 4% of the proposals.
The remaining two projects are on hold while EPA evaluates the budget for fiscal 1996.
The PETC-Pavilion effort remains a good project, notes Charles Drummond, systems engineering and analysis director at PETC, because it would use coal properties and operating conditions to train a neural network to replace a CEM.
Utilities with boilers larger than 25 MWe are required by the Clean Air Act to install CEMs, with average cost hovering at $150,000.
By comparison, a neural network software package, with accuracy Winter 1996
B
approaching that of a CEM, sells for a few thousand dollars.
Industry analysts forecast that about 1,100 new stacks in the U.S. need CEMs to comply with federal regulations.
The monitors also present long-term maintenance problems--electronic parameters tend to drift-incurring costs beyond the purchase and installation price.
A neural network, in contrast, is maintenance-free and could periodically update itself through retraining to include the effects of boiler age.
To cut costs while still complying with the Clean Air Act, a utility could lease a CEM long enough to train the network and convince EPA that the network is as accurate as the monitor, explains Ekmann.
Industrial sources, thus far, are not required to use CEMs, but they aren't waiting for a government-sanctioned invitation.
Nervous that the monitors may soon be forced on industrial boilers, the Council of Industrial Boiler Owners is joining the two government agencies in searching for an acceptable alternative to costly compliance.
By approving neural networks as alternatives to CEMs, says Wildman, "EPA can ask more from industrial users.
It can ask the user to develop a means of measuring NOx not prohibitive from a cost point of view.
"
PETC
Review
13
This article has been excerpted from the
Inquiries about obtaining this publication should be directed to: Dr. Harold F. Chambers, Jr.
PETC Review P.O. Box 10940 Pittsburgh, PA 15236-0940 Phone: 412/892-6060 Fax: 412-892-4604
