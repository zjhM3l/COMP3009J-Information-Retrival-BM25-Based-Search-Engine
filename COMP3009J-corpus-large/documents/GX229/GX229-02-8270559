Census 2000 Testing, Experimentation, and Evaluation Program Updated May 2002 ** For program changes since the release of this document, please see "Program Modifications Since May 2002".
P LA N N IN G , RESEA RC H , AN D EVA LUATIO N D IVISIO N "Beyond the Horizon"
PRED
U .S. C en sus B u reau
This page intentionally left blank.
May 2002
Table of Contents Page Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i Part A: The Census 2000 Testing, Experimentation, and Evaluation Program Overview . . . . .
A-1 Introduction . . . . . .
What We Will Learn What We Will Learn Planning for the Next Conclusion . . . . . . .
.......
from the from the Decade .......
.................
Evaluation Program Census 2000 Testing ................
.................
.... ... and ....
....
..............
..............
Experimentation ..............
..............
.......
.......
Program .......
....... ... ... .. ... ... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A-3 A-4 A-6 A-7 A-8
Part B: The Census 2000 Testing and Experimentation Program . . . . . . . . . . . . . . . . . . . . . . . .
B-1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Census 2000 Alternative Questionnaire Experiment . . . . . . . . . . . . . . . . . .
Administrative Records Census 2000 Experiment . . . . . . . . . . . . . . . . . . .
Social Security Number, Privacy Attitudes, and Notification Experiment .
Response Mode and Incentive Experiment . . . . . . . . . . . . . . . . . . . . . . . . .
Census 2000 Supplementary Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Use of the Employee Reliability Inventory File for Nonresponse Followup Ethnographic Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
..........
..........
..........
..........
..........
..........
Enumerators .......... . . . . . . . . . . . . .
.. . . . . . . . . . . . . . . . . . . . .
B-3 B-5 B-7 B-9 B-11 B-13 B-15 B-17
Part C: The Census 2000 Evaluation Program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
C-1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A: Response Rates and Behavior Analysis . . . . . . . . . . . . . . . . .
B: Content and Data Quality . . . . . . . . . . . . . . . . . . . . . . . . . . .
C: Data Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
D: Partnership and Marketing . . . . . . . . . . . . . . . . . . . . . . . . . . .
E: Special Places and Group Quarters . . . . . . . . . . . . . . . . . . . .
F: Address List Development . . . . . . . . . . . . . . . . . . . . . . . . . .
G: Field Recruiting and Management . . . . . . . . . . . . . . . . . . . .
H: Field Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
I: Coverage Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
J: Ethnographic Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
K: Data Capture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
L: Processing Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
M: Quality Assurance Evaluations . . . . . . . . . . . . . . . . . . . . . . .
N: Accuracy and Coverage Evaluation Survey Operations . . . .
O: Coverage Evaluations of the Census and of the Accuracy and Coverage Evaluation Survey . . . . . . . . . . . . . . . . . . . . . . . . .
P: Accuracy and Coverage Evaluation Survey Statistical Design Q: Organization, Budget, and Management Information System R: Automation of Census Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
C-5 .
C-7 C-11 C-17 C-19 C-21 C-25 C-31 C-33 C-37 C-41 C-43 C-45 C-49 C-51 C-57 C-63 C-65 C-67
.... and ... ....
.. sti ..
..
... mat ... ...
... io n ... ...
.. .
..
..
May 2002
A-4
Part A:
The Census 2000 Testing, Experimentation, and Evaluation Program Overview
May 2002
A-5
This page intentionally left blank.
May 2002
A-6
The Census 2000 Testing, Experimentation, and Evaluation Program Introduction In their final report on the design of Census 2000, the Commerce Secretary's 2000 Census Advisory Committee concluded: "What everyone wants is as simple as A-B-C...
A Better Census."
But how will we know if we achieve a better census in 2000, and how will we build a better one for 2010? An important source for answering these questions will be the Census 2000 Testing, Experimentation, and Evaluation Program.
Besides being used to assess Census 2000, this program will help design testing for early 2010 Census planning and provide information for the American Community Survey, Master Address File Updating System, and other Census Bureau censuses and surveys.
As other countries look to the U.S. Census Bureau as a leader in techniques and methodologies, the results of the Census 2000 Testing, Experimentation, and Evaluation Program may also help them in making more informed decisions in designing their censuses.
Important factors affecting the next decade include:
C C C C C C C C
The implementation of the American Community Survey in lieu of a long form census data collection; The ability to dramatically change the 2010 Census when collecting only short form census data; A continually maintained housing unit address frame; The modernization of the Master Address File Updating System; The role of administrative records in the 2010 Census, the American Community Survey, and address list development; The changing community role in the census as manifested through partnerships, governmental activities, and constituent groups; The impact of a rapidly changing technological environment on census data collection, capture, processing, and dissemination; Difficulty in eliciting public response to censuses and surveys; and
May 2002
A-7
C
The ability to limit the potential for duplicate responses when alternative ways of responding to the census are offered.
What We Will Learn from the Evaluation Program The Census 2000 Evaluation Program will measure the effectiveness and impact on data quality of the Census 2000 design, operations, systems, and processes.
It will provide measures of the success of Census 2000 and its operations which are of interest to internal and external stakeholders.
For example, it will inform data users and stakeholders about data quality and limitations of the data, help explain the quality of census data, and provide information needed for historical comparability of census methods and procedures.
This also will inform planning and development of the 2010 Census, the American Community Survey, and the Master Address File Updating System.
It will help determine what simplifications can be made to the overall 2010 Census design, assist in operational planning, and inform questionnaire development and alternative data collection methodologies.
Over 1001 studies are planned in the following areas: Response Rates 
Many of the issues we are trying to understand with these evaluation studies are described below.
In some cases, we will be able to reach firm conclusions, while in others it will be more difficult to disentangle effects of the census procedures from the external environment.
C C
The effectiveness of the Partnership and Marketing Program's paid advertising in changing awareness and mail response behavior of various groups and hard-to-count populations; Whether national and regional objectives of the expanded Partnership Program were accomplished;
Refer to "Part C: The Census 2000 Evaluation Program Â­ Introduction" for more information on the planned evaluations and recent changes in the program.
1
May 2002
A-8
C
The effectiveness of operations used to build, update, and assign geographic codes to the Census 2000 address list.
This will involve studies of the Master Address File, the Census Bureau's geographic database, the Postal Service's Delivery Sequence File, field operations, and partnership operations such as the Local Update of Census Addresses; Coverage rates for various demographic groups and areas, as measured by the Accuracy and Coverage Evaluation Survey and by demographic analysis; The effectiveness of the various Accuracy and Coverage Evaluation Survey operations in measuring errors in the census; The relative effectiveness of various operations designed to improve overall coverage or reduce differential coverage errors for hard-to-enumerate groups and areas; The use, effectiveness, and data quality of various modes available for responding to the census (Mail, Nonresponse Followup, Internet, Telephone Questionnaire Assistance, Be Counted forms); The coverage, content, comparability, and sources of information used to construct the group quarters frame for the decennial census (and American Community Survey); The use and effectiveness of language assistance guides and non-English language questionnaires; The success of the Data Capture System, including the Optical Mark Recognition, Optical Character Recognition, and operational problems; The ability of various field and processing operations to identify and unduplicate multiple responses for the same household or individual; The effectiveness of recruiting, training, and pay strategies in obtaining the workforce needed to conduct field operations; The completeness and accuracy of data, as measured by item imputation rates, proxy rates, and comparisons to external benchmarks, for both mail returns and enumerator completed questionnaires; The effects of the new race and Hispanic origin questions on the content and quality of data, particularly in comparison to data based on different questions in previous censuses; The reliability, functionality, maintenance, and security needs of many of the major automated systems designed to support Census 2000; and The effectiveness of the quality assurance strategy used for Census 2000.
May 2002
C C C C
C C C C C C
C C C
A-9
What We Will Learn from the Census 2000 Testing and Experimentation Program The primary role of the Census 2000 Testing and Experimentation Program is to help guide planning for the 2010 Census and the American Community Survey.
The American Community Survey began in 1996 and planning for the 2010 Census began in 1997.
These early efforts identified testing and experimentation that needed to occur during Census 2000 - that is, under real decennial census conditions of paid advertising and national attention, partnerships, and the sheer magnitude of efforts such as hiring over 500,000 temporary employees.
The seven studies are: Census 2000 Alternative Questionnaire Experiment Administrative Records Census Experiment Social Security Number, Privacy Attitudes, and Notification Experiment Response Mode and Incentive Experiment Census 2000 Supplementary Survey Use of Employee Reliability Inventory File for Nonresponse Followup Enumerators Ethnographic Studies Key things we will learn from these studies include:
C
An assessment of different questionnaire design and content on coverage and data quality, including the effects of the amount and presentation of residence rules, instrument design, and a comparison of the 1990 race question with that used in 2000; An assessment, under decennial conditions, of the use of various types of administrative records as a primary data collection tool - two major approaches will be studied; Public response and the effects on mail and item response to a request for Social Security Numbers on the census short form, and to two variations of a notification about the Census Bureau's proposed use of administrative records obtained from other government agencies; Public response to alternative modes of response such as Computer-Assisted Telephone Interviews, interactive voice response, and the Internet; The effects of offering alternative self-administered data collection modes, as well as offering an incentive to respondents who use these modes; The operational and technical feasibility of collecting long form data using the methods of the American Community Survey, a key element in validating the plan to eliminate the long form from the 2010 Census;
C C
C C C
May 2002
A-10
C
The validity and feasibility of using a noncognitive test of personality based competencies to select interviewers with better interpersonal skills, thereby reducing turnover and improving work performance; and Qualitative data about response behavior for hard-to-enumerate subgroups of the population.
C
Planning for the Next Decade Results from the Census 2000 Testing, Experimentation, and Evaluation Program will help inform the Census Bureau's efforts to achieve the following objectives for the 2010 Census and other programs:
C C C C C
Improve coverage of the population and reduce the differential undercount; Improve the accuracy of responses and locating people geographically; Increase mail response rates and reduce field activities; Maintain and refine an open process with all stakeholders throughout the decade while increasing the confidence of our customers; and Spread the cost of data collection and updating the address list more evenly throughout the decade to reduce risk, simplify logistics, and improve manageability.
We will use a three pronged strategy to achieve these goals:
C
Enhance the Master Address File and geographic database through modernization initiatives such as a web-based system, global positioning system, and an on-going Local Update of Census Address (LUCA) program.
This will: Â­ Â­ Â­ enhance LUCA; directly attack the issues of a complete and unduplicated address list; and facilitate automation and electronic collection.
C
Through the American Community Survey, collect and tabulate long form data every year.
This will: Â­ Â­ Â­ expand our ability to target; simplify the 2010 process allowing us to focus on coverage; and provide long form data on a flow basis.
May 2002
A-11
C
Reengineer the 2010 Census process through early planning, taking into account opportunities afforded by no long form and an enhanced Master Address File.
Using technology and a short-form only census will: Â­ establish a flexible cost effective infrastructure that will facilitate coverage improvement; Â­ set up a data flow design to allow for efficiencies to the process; and Â­ establish a foundation upon which the "perfect census" can be built.
The Census 2000 Testing, Experimentation, and Evaluation Program will help us to address key planning questions for this decade:
C C C C C C C
Do we need to lengthen or shorten time periods for census operations for quality or operational reasons? Are there any unforeseen operational difficulties when collecting long form data using the methods of the American Community Survey? What is the overall effect of a continuously maintained address file? How can we be most effective with partnerships, promotion, and advertising? What is the potential impact of using administrative records? How accurate are our sample design and procedures for estimating total and differential undercount? What is the impact on field activities and infrastructure of hiring and training many more enumerators than are needed for decennial operations in order to compensate for expected turnover? Which response options are most effective?
C
Conclusion The design of Census 2000 is by far the most ambitious decennial census in history, particularly in its use of an open planning process, promotion, partnerships, new technologies, statistical methodology, and alternative methods for hard-to-count populations and areas.
Yet as our nation continues to grow and the need for rapid and accurate data continues, all of these approaches need to be further refined and developed to meet the challenges of providing data in the 21st Century - more data needs at lower levels of geography on a more timely basis.
May 2002
B-12 The Census 2000 Testing, Experimentation, and Evaluation Program will assist the Census Bureau in evaluating Census 2000 and in exploring new survey procedures in a census environment.
It builds the foundation for making early and informed decisions about the role and scope of the 2010 Census in the federal statistical system and its interaction with the American Community Survey and the Master Address File Updating System.
This work provides critical analysis and information for Census Bureau planning and implementation of decisions for the 2010 Census and the American Community Survey.
Part B:
The Census 2000 Testing and Experimentation Program
May 2002
B-13
May 2002
B-14 This page intentionally left blank.
May 2002
B-15
The Census 2000 Testing and Experimentation Program Introduction A successful decennial census, one that is responsive to the nation's changing needs, cannot be achieved without early planning.
Many key issues for Census 2000, such as declining public cooperation and tighter funding restrictions, were already being studied in the late 1980s.
Fundamental operational changes, such as those designed to improve the process for capturing information on the census questionnaires, came from this early research.
For a decennial census, much lead time is needed to first identify and test promising new procedures, make adjustments, and retest as needed.
Substantial lead time is particularly necessary for the procurement and testing of many different types of equipment that must be in place to conduct the decennial census.
Early in 1997, the Census Bureau formed a team to develop the Census 2000 program of testing and experimentation.
The tests and experiments were conducted concurrently with Census 2000 because the decennial census environment provided the best possible conditions to learn about the value of new or different methodologies.
Research conducted during the decennial census is expected to guide future decennial census designs, but also provide valuable information for use by other areas of the Census Bureau.
Planned Tests and Experiments Summary descriptions of the tests and experiments conducted in Census 2000 are provided on the following pages.
May 2002
B-16
This page intentionally left blank.
Census 2000 Alternative Questionnaire Experiment (AQE2000) May 2002
B-17 Overview This experiment was designed to manipulate three independent questionnaire design components.
The first component evaluates the effects of the amount and presentation of the residence rules on the short form; that is, in comparison to the current presentation would a briefer and reformatted presentation of the rules improve data quality? Since this is a coverage issue, a reinterview was conducted.
The second component examined the presentation of the race question to determine whether changes in the way the race questions were asked in the 1990 and 2000 censuses affect the quality and content of race data.
Specifically, it evaluated the combined effects of variant question wording, format, content, and design on race data quality and content.
The third component pertains to the long form, specifically in regard to the design of the skip instructions to determine whether the current format facilitated respondent's navigation through the form correctly.
"Skip to" and "go to" instruction variations were examined.
Information learned about the long form will advise implementation of the American Community Survey.
Objectives The objectives of this experiment were to continue efforts to develop a user friendly mail-out questionnaire that can be completed accurately by respondents and to evaluate the effects of questionnaire changes on the data.
Corresponding to the variables described above, the specific objectives were: 1) to compare the Census 2000 short form, defined as containing a full set of residence rules, with a revised form that contains an alternate presentation of the rules, 2) to compare the Census 2000 short form presentation and sequencing of the race question, including its provision for marking multiple categories, to that of the 1990 presentation and instructions, and 3) to compare the standard skip instruction on the Census 2000 long form with four revised formats.
May 2002
B-18
This page intentionally left blank.
Administrative Records Census 2000 Experiment (AREX 2000) May 2002
B-19 Overview The Plan for Census 2000 explicitly called for experimentation with an administrative records census for two reasons: 1) use of administrative records as the primary data collection method has tremendous potential for cost savings, and 2) significant testing of administrative records was not done as part of the 1990 Census testing and experimentation program and, as a result, the Census Bureau was not sufficiently prepared to include administrative records in the Census 2000 design.
The potential benefit of an administrative records census is to reduce the cost and response burden of direct data collection.
The AREX 2000 explored two methods for conducting an administrative records census.
In both methods, national-level administrative records were assembled, unduplicated using Social Security Numbers, and assigned block-level geographic codes.
Records for the selected test sites (approximately one million housing units in five counties) were extracted and tallied at the census block level.
The two methods differ in their use of the Master Address File to create a universe (frame) of housing units.
The first method did not use the Master Address File but provided only population counts at the block level.
The second method matched administrative records to addresses on the Master Address File and reconciled differences through field operations.
This method provided both population and housing unit counts at the block level.
The experiment included the following field/mailout operations: 1) a clerical geocoding operation to be conducted at selected Regional Census Centers, 2) a field address verification operation, and 3) a mailout to P.O. Box and rural-style addresses to obtain geocodable house number/street name information.
Objectives The AREX 2000 compared two methods for conducting an administrative records census to Census 2000 and evaluated the results and costs.
The data analysis for the experiment included comparisons of site, census tract and block level population and housing counts from AREX 2000 and Census 2000.
The analysis also examined the similarities and differences of population characteristics (age, gender, race/ethnicity) and simulate the replacement of Census 2000 nonresponse household enumerations with administrative record information.
Secondary objectives included collecting relevant information that was only available in 2000 to be used for ongoing testing and planning for administrative records use in the 2010 Census and for comparing an administrative records census to other potential 2010 methodologies.
May 2002
B-20
This page intentionally left blank.
May 2002
B-21 Social Security Number, Privacy Attitudes, and Notification Experiment (SPAN) Overview The purpose of the SPAN was to obtain behavioral and attitudinal data on several topics related to the use of administrative records.
This included how the public responded to requests for Social Security Numbers (SSNs) on decennial census questionnaires, how the public responds to differently worded notifications about the Census Bureau's use of administrative records, and on what were the public's attitudes on privacy and confidentiality pertaining to the notion of an administrative records census.
The SPAN consisted of two components.
The first component collected data on requesting the SSN and the use of differently worded notifications.
The second component involved a telephone survey that measured the public's attitudes on privacy and confidentiality issues.
Objectives for Component 1: Specific objectives were to determine: 1) what effect a request for the SSN for every household member has on mail and item response, 2) what effect a request for an SSN for only the person completing the questionnaire has on mail and item response, 3) the accuracy of the respondent-provided SSNs, and 4) what effect different notifications on the Census Bureau's possible use of administrative records has on mail and item response rates.
The methodology for achieving these objectives involved the mailout of seven short form and three long form panels -- each panel containing a 5,000 sample -- for a total of 50,000 forms during Census 2000.
The long form panels included only the notification test with no requests for SSNs.
There were two notifications -- referred to as "general" and "specific."
Each notification was included in the cover letter and described how or why the Census Bureau may use administrative records data from other Federal agencies.
A "general" notification mentioned the Census Bureau's possible use of statistical data from other Federal agencies, while the "specific" notification goes further to mention actual Federal agencies, such as the Internal Revenue Service, Social Security Administration, and "agencies providing public housing assistance."
Objectives for Component 2: The second component of the SPAN was a telephone survey that measured the public's attitudes on privacy and confidentiality issues pertaining to an administrative records census.
This survey included pre- and post-measurements to Census 2000 to enable examination of the census environment's effect on privacy attitudes.
The premeasurement took place before the national paid advertising and field recruiting campaigns.
The post-measurement occurred shortly after Census Day, April 1, 2000.
Each measurement group was a national sample of 2,000 households.
Specific objectives were to: 1) determine the
public's opinion of the Federal government and the Census Bureau in general, 2) assess change in the public's attitudes on privacy-related issues using results from studies conducted in 1995 May 2002
B-22 and 1996, and 3) determine the public's opinion of the Census Bureau's testing on expanding the use of administrative records, possible interest in collecting SSNs in the future, and the notion of an "administrative records census."
May 2002
B-23 Response Mode and Incentive Experiment (RMIE) Overview This experiment measured the effect of an incentive and/or option of alternative electronic modes of collection on response to the census short form.
Since 1970, response to the mailed form has declined and labor costs to visit nonresponding households have greatly increased.
To address these problems, the Census Bureau explored other methods and technologies to count the population, such as incentives, telephones, and the Internet.
This experiment determined what effect an incentive has on getting respondents to answer the census using one of three electronic modes of collection.
The effectiveness of the incentive also was measured on households not responding to the mailout of the standard Census 2000 questionnaire.
The alternative modes of collection were:
C
Operator telephone interview.
This is referred to as reverse computer-assisted telephone interview (Reverse CATI).
The cover letter accompanying the paper questionnaire encouraged response using a toll-free telephone number.
A telephone interviewer administered the questionnaire over the phone.
Computer telephone interview.
This is an interactive voice response system called the Automated Spoken Questionnaire (ASQ).
The cover letter accompanying the paper questionnaire encouraged response using a toll-free telephone number.
Instead of an operator taking the interview, an interactive voice response (IVR) system prompted the respondent through the short form instrument.
Internet.
The cover letter accompanying the paper questionnaire encouraged response using the Internet and included a dedicated uniform resource locator (URL) for the data collection.
C
C
Employing the collection modes listed above, this experiment incorporated two treatments: response mode and incentive, each with three panels.
There also was a control group consisting of three panels which served as the universe for the response phase of the experiment.
The total mailout for all panels was 35,380 households.
The incentive was a telephone calling card worth thirty minutes of free long distance service which was activated after response.
Data analysis was conducted on seven experimental components that included: 1) initial mailout/operator assistance, 2) nonresponse, 3) ASQ - name recognition, 4) ASQ - customer satisfaction, 5) Internet Usage Survey (telephone followup), 6) Internet Customer Satisfaction Survey (administered on the Internet), and 7) Internet administrative data.
Objectives May 2002
B-24 This experiment has the following key objectives:
C C C C
Determine the effect of incentives on cooperation rates, household cooperation, item nonresponse, and on sufficient completeness.
Determine effect of response mode on cooperation rates, household response, and item nonresponse.
Determine the effect of incentives and response mode on the census nonresponding households.
Assess the operational benefits of offering electronic modes for response and data collection and capture.
May 2002
B-25 Census 2000 Supplementary Survey Overview Census 2000 included a long form for 1-in-6 households across the country.
Essentially the same process has been used since 1940 to collect basic socioeconomic information (such as educational, marital, and veterans' status; housing characteristics; and commuting patterns) for all geographic areas of the United States, ranging from the national down to the census tract level.
In spite of the efficiencies of using the decennial census to collect this critical socioeconomic data, there is strong interest in moving away from this approach -- both to simplify the census process and to provide more current and more accurate data for federal, state and local users.
In response to this interest, Census 2000 included, in addition to a traditional long form, a supplementary survey designed as the operational feasibility test of collecting long form data throughout the country during the same time frame but in a process separate from the census.
Objectives The objective of the Census 2000 Supplementary Survey was to demonstrate the operational and technical feasibility of collecting the full range of socioeconomic data gathered on the decennial census long form using a different questionnaire and estimation methodology.
To accomplish this objective, the Census 2000 Supplementary Survey was conducted during Census 2000 using an existing questionnaire -- that of the American Community Survey.
Results will inform the process of removing the long form from the census.
May 2002
B-26
This page intentionally left blank.
Use of the Employee Reliability Inventory File for Nonresponse Followup Enumerators Overview May 2002
B-27 The Office of Personnel Management (OPM) reported that the tests used to hire decennial staff, while valid, do not assess an important aspect of the knowledge, skills, and abilities needed for successful performance -- interpersonal skills.
This experiment will help determine if the Employee Reliability Inventory (ERI) meets each of three criteria for a valid selection test and if it is appropriate for use in selecting decennial census enumerators.
To be considered a valid selection aid, the personality-based competencies measured by a noncognitive test should: 1) be job-relevant, 2) have no between-group differences, and 3) be subject-related.
To measure the noncognitive competencies of census new hires, an already existing noncognitive instrument from the testing market (ERI) was administered to a sample of people hired to be nonresponse followup enumerators.
The research will answer the following questions:
C Does the use of a noncognitive test significantly add to the overall predictability of job performance and tenure? C Can we identify which traits actually distinguish those who stay from those who do not and those who show the best performance from those who do not? C Can we document that decennial enumerators who left before the completion of an operation performed differently on the ERI than those who stayed? C Can we use the ERI to reliably predict turnover or job success? Objectives The overall objective of this study was to determine if an existing noncognitive test provided a reliable and valid measure of interpersonal skills that can be used by the census to make more precise employee hiring decisions.
The goal was to determine if the Census Bureau could reduce interviewer turnover and improve interviewer work performance by improving enumerator selection tools through the use of a commercial noncognitive test -- the ERI.
May 2002
B-28
This page intentionally left blank.
Ethnographic Studies Overview May 2002
B-29 The Census Bureau used ethnographic techniques to study survey coverage as early as 1971.
The National Academy of Science's Panel on Decennial Census Methodology, established by the Census Bureau in 1984, recommended that the Census Bureau undertake a series of participant observation coverage studies in selected areas.
Exploratory ethnographic research was initiated in a number of communities to identify and explain the complex behavioral processes that lead to underenumeration.
Based on the experience obtained in preliminary research, the Census Bureau launched its most ambitious phase of ethnographic studies associated with the 1990 Census.
More than 40 additional exploratory and ethnographic studies and evaluations were conducted on a wide range of populationsÂ­such as the homeless, migrant workers, African Americans, Latinos, American Indians, and AsiansÂ­and issues such as respondents' understanding of census language and concepts, and other types of communications.
Objectives Ethnographic studies conducted in association with Census 2000 provided new insights that can be used to improve coverage of selected segments of this nation's population.
The following studies reflect selected social and demographic aspects in American society that are important to explore from an ethnographic perspective.
This perspective, grounded in the actual behavior of respondents, can offer insights which other methods may not capture.
Protecting Privacy: Information, Trust and Technology in the Decennial Census and Demographic Surveys: The goal of this project was to conduct a qualitative study of belief structures that influence survey respondents' perceptions of, and reactions to, survey information requests, focusing on privacy concerns.
This study explored how respondents assess the consequences of survey participation and survey response, their sense of information ownership, their reactions to confidentiality statements, and their reasons for choosing to participate in survey data collections.
Complex Households and Relationships in the Decennial Census and Demographic Surveys: This ethnographic research project had three objectives: 1) to explore the range and functioning of complex households within different ethnic groups in the United States, 2) to examine how the response categories of the decennial relationship question capture the emerging diversity of household types, and 3) to compare the household composition and relationship information collected by the ethnographic interviews to those in Census 2000.
This study was designed to assess how well census methods, questions, relationship categories, and household composition typologies describe the emerging diversity of household types in this country.
Six ethnographers or teams each conducted 25 ethnographic interviews with a selected ethnic/race group: African Americans, Hispanics, Inupiaq Eskimos, Koreans, Navajos, or Whites.
Generation X Speaks Out on Censuses, Surveys, and Civic Engagement: An Ethnographic Approach: The purpose of this nationwide ethnographic research was to examine civic engagement, behaviors, and attitudes towards censuses and surveys among Gen-Xers May 2002
C-30 (individuals born during the years 1968-1979) from varied socioeconomic backgrounds and ethnicities, including individuals from hard-to-enumerate categories, such as young minority males and immigrants.
Patterns of civic engagement have consequences for government data collection efforts in terms of survey nonresponse, trust and privacy concerns, policy-oriented issues and effective educational outreach campaigns.
Millennial Generation individuals (14-18 years of age) were also interviewed in order that comparative life-cycle experiences and cultural explanations emerge with regard to census and survey nonresponse, government engagement, and civic responsibility and obligation.
Part C: The May 2002
C-31
Census 2000 Evaluation Program
May 2002
C-32
This page intentionally left blank.
May 2002
C-33
Census 2000 Evaluation Program Table of Contents Page Introduction ...............................................................
C-5 A: Response Rates and Behavior Analysis ........................................C-7 B: Content and Data Quality ..................................................C-11 C: Data Products ...........................................................C-17 D: Partnership and Marketing .................................................C-19 E: Special Places and Group Quarters ..........................................C-21 F: Address List Development .................................................C-25 G: Field Recruiting and Management ...........................................C-31 H: Field Operations .........................................................C-33 I: Coverage Improvement ....................................................C-37 J: Ethnographic Studies .....................................................C-41 K: Data Capture ................
...........................................C-43 L: Processing Systems ......................................................C-45 M: Quality Assurance Evaluations .............................................C-49 N: Accuracy and Coverage Evaluation Survey Operations ..........................C-51 O: Coverage Evaluations of the Census and of the Accuracy and Coverage Evaluation Survey .......................................................C-57 P: Accuracy and Coverage Evaluation Survey Statistical Design and Estimation .........C-63 Q: Organization, Budget, and Management Information System ......................C-65 R: Automation of Census Processes .
...........................................C-67
May 2002
C-34
This page intentionally left blank.
May 2002
C-35
Introduction
2
For over half a century, the Census Bureau has conducted a formal evaluation program in conjunction with each decennial census.
For Census 2000, the Evaluation Program will assess the effectiveness of key operations, systems, and activities in order to evaluate the current census and to facilitate planning for the 2010 Census, the American Community Survey, and the Master Address File Updating System modernization.
The Census 2000 Dress Rehearsal in 1998 included evaluations of questionnaire design, field operations, data processing, and estimation.
Over 40 evaluation studies were used to inform the final Census 2000 design.
As originally planned, the Census 2000 Evaluation Program more than tripled this effort with nearly 150 evaluations.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
We attempted to obtain the best balance of resources needed for: Â· completing and releasing Census 2000 data products, and Â· conducting key Census 2000 evaluations.
To accomplish this, we combined important aspects of similar evaluations and dropped those that were less critical for 2010 Census planning.
We dropped components of evaluations for which analytical data were not available.
Additionally, some evaluations planned for the Accuracy and Coverage Evaluation were no longer needed when the decision was made not to adjust the Census 2000 population counts.
It was determined that some of the reports that were developed in an expedited manner to inform the Executive Steering Committee for Accuracy and Coverage Evaluation Policy (ESCAP) decisions were sufficiently complete and informative to answer the research questions from the earlier-planned evaluation reports.
As a result, the Census 2000 Evaluation Program, which previously included 149 evaluation reports, will now include 115, of which 18 are ESCAP reports.
These reports and their corresponding ESCAP reports are noted in the following section for evaluation report descriptions.
To review the ESCAP reports on the Internet, go to http://www.census.gov/ and search on "ESCAP."
The evaluations fall into 18 broad categories covering response rates, data quality, partnership and marketing, address list development, field operations, coverage improvement, data capture and processing systems, the Accuracy and Coverage Evaluation Survey, and others.
The evaluations speak to issues of quality, plausibility, feasibility, accuracy, effectiveness, and value, and will provide a comprehensive assessment of the operations and outcomes of the census.
Although the scope of the Census 2000 Evaluation Program is well defined, as more data become available and review and analysis progresses, there may be additional program changes.
May 2002
2
C-36 Every evaluation in the program was approved by the Census 2000 Evaluations Executive Steering Committee.
The steering committee includes the Associate Director for Decennial Census, the Associate Director for Methodology and Standards, division chiefs, and other census experts.
All evaluations undergo an extensive Quality Assurance process.
Evaluation methodologies and study plans are critiqued by a wide audience of census experts.
Specifications, field procedures, and computer programs are documented, reviewed, and approved by appropriate census staff.
Finally, each evaluation report is reviewed for factual accuracy and then sent to the Census 2000 Evaluations Executive Steering Committee and Census Bureau Executive Staff for their approval.
Results from the evaluations, as well as relevant results from tests and experiments, will be synthesized into topic reports that address broad census subjects that cross categories.
Current plans are to prepare reports for the following topics: address list development, partnership and marketing, coverage improvement, data collection, data processing, data capture, automation of census processes, coverage measurement (Accuracy and Coverage Evaluation Program), content and data quality, response rates and behavioral analysis, race and ethnicity, ethnographic studies, Puerto Rico, special places and group quarters, and privacy.
For each of the 18 categories, this section provides an "Overview" and a "What Will We Learn?" section, followed by a brief description of each planned evaluation.
May 2002
C-37 A: Response Rates and Behavior Analysis
Overview These evaluations examine various modes for providing responses to the census.
We will study the use of the telephone and Internet as response options.
The effectiveness of mailing practices and the targeted dissemination of forms will also be assessed.
These evaluations focus on respondent behavior and how that behavior impacts response rates (i.e., mailback, telephone, and Internet).
Findings from these evaluations will identify methods that can be used in future censuses to improve the overall response rates.
What Will We Learn?
The findings from these evaluations will answer a number of critical questions about how quickly the U.S. population responded to Census 2000.
From a technical standpoint, the use of an Internet Questionnaire Assistance module will demonstrate the utility of employing the "most current" technologies and provide insight into respondent perception of using this mode for requesting information or completing a questionnaire.
Likewise, an enhanced telephone questionnaire assistance program that is user-friendly and comprehensive will provide further insight into respondent needs and preferences.
Analyzing mail response/return rates (by form type, demographics, and geography) and mailing practices, such as tracking undeliverable questionnaires, will provide insight into improving overall response rates.
Assessment of the Be Counted Campaign will help determine demographic groups that responded via the Be Counted Campaign.
We also will examine the frequency of using language assistance guides and questionnaires in languages other than English, along with the number of returned non-English questionnaires.
May 2002
C-38
May 2002
C-39 Response Rates and Behavior Analysis Evaluations (A.1.a) Telephone Questionnaire Assistance Operational Analysis The Census 2000 Telephone Questionnaire Assistance system was developed with contractor support to provide the following services to respondents: 1) helping them complete questionnaires, 2) providing questionnaires (English forms only) and foreign language guides upon request, and 3) conducting short form questionnaire telephone interviews when necessary.
This operational evaluation assesses calling patterns, caller behavior, and system performance.
(A.1.b) Telephone Questionnaire Assistance Customer Satisfaction Survey This evaluation focuses on customer reaction to the Census 2000 Telephone Questionnaire Assistance program.
It includes analyses in the following areas: accessibility, ease of use, overall satisfaction with the assistance and appropriateness of the information provided.
(A.2.a) Internet Questionnaire Assistance Operational Analysis (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(A.2.b) Internet Data Collection Operational Analysis For Census 2000, respondents had the opportunity to complete the short form questionnaire on the Internet.
This was the first time a decennial census had used this data collection mode.
Since there is no background data, a general evaluation of the Internet data collection mode is planned on what might be expected in terms of frequency of use.
(A.2.c) Census 2000 Internet Web Site and Questionnaire Customer Satisfaction Survey Customer satisfaction surveys are used to measure respondent satisfaction with both the Internet Questionnaire Assistance and the Internet Data Collection programs.
(A.3) Be Counted Campaign for Census 2000 The Be Counted Campaign made blank questionnaires available at convenient locations for people who believed they were left out of Census 2000.
This evaluation will examine person and housing unit coverage gains from the campaign along with the characteristics of those enumerated on Be Counted forms.
This evaluation also will assess the impact on the Master Address File through documentation of housing unit adds resulting from this program, and it will evaluate our ability to geocode and process Be Counted forms.
(A.4) Language Program - Use of Non-English Questionnaires and Guides This study will document how many housing units were mailed the advance letter about requesting a non-English questionnaire, by state and type of enumeration area (e.g., mailout/mailback, update/leave, etc.); how many non-English forms were requested, completed, and checked in; and the frequency of requests for non-English short and long forms.
This study also will document the number of language assistance guides requested through Telephone Questionnaire Assistance, Questionnaire Assistance Centers, and the Internet, along with an May 2002
C-40 analysis of which languages were most often requested, whether the requests were clustered geographically, and how many requests for a language assistance guide resulted in a mail returned form.
(A.5) Response Process for Selected Language Groups This evaluation will provide insight into how Spanish, Vietnamese, and Russian speaking households coped with the census questionnaire in Census 2000.
Specifically, we will look at how these non-English speaking long form households were enumerated.
We will assess their use of language guides, Questionnaire Assistance Centers, Telephone Questionnaire Assistance, and their experience with the English form.
(A.6.a) U.S. Postal Service Undeliverable Rates for Census 2000 Mailout Questionnaires For Census 2000, the questionnaire mailout/mailback system provided the primary means of enumeration.
This type of enumeration was conducted mainly in urban and suburban areas, but also in some rural areas that contained city-style address (house number/street name) systems.
This evaluation examines the rates at which housing units were classified by the U.S. Postal Service as "undeliverable as addressed" (UAA) for varying levels of geography; the occupancy status of those housing units; demographic characteristics for housing units that were deemed undeliverable but had a final status of occupied; the effect that undeliverable questionnaires had on nonresponse rates; and the check-in pattern of UAA questionnaires according to date of receipt.
(A.6.b) Detailed Reasons for Undeliverability of Census 2000 Mailout Questionnaires by the USPS This evaluation further examines the issue of the undeliverability of census mailout questionnaires.
After the U.S. Postal Service determined that mail pieces were "undeliverable as addressed" (UAA), the Census Bureau attempted to deliver these cases at the Local Census Office level.
This evaluation assesses the quantity of questionnaires designated as UAA and the distribution of the UAA questionnaires according to reason for undeliverability.
(A.7.a) Census 2000 Mailback Response Rates Housing units in mailout/mailback and update/leave enumeration areas were asked to return questionnaires in postage paid envelopes.
Those questionnaires were received and checked in at Data Capture Centers.
This evaluation examines mail response rates at varying levels of geography and quantifies information about incoming questionnaires according to form type and timing with respect to critical operational dates.
(A.7.b) Census 2000 Mail Return Rates Housing units in mailout/mailback and update/leave enumeration areas were asked to return questionnaires in postage paid envelopes, and once all followup operations were complete, those housing units were assigned a final status.
Only the housing units assigned to receive an update/leave or mailout/mailback questionnaire with a final status of occupied on Census Day (April 1, 2000) are factored into the mail return rates.
Data on mail return rates provide more May 2002
C-41 accurate measures of cooperation than mail response rates, for which the denominator also includes units that turned out to be vacant or non-existent on Census Day (April 1, 2000).
This evaluation examines mail return rates at varying levels of geography, quantifies information about incoming questionnaires from occupied housing units according to form type and timing with respect to critical operational dates, and provides return rate data according to certain housing unit demographic characteristics.
(A.8) Puerto Rico Focus Groups on Why Households Did Not Mail Back the Census 2000 Questionnaire For Census 2000, the Census Bureau conducted an update/leave enumeration for the first time in Puerto Rico.
That is, census enumerators left a questionnaire at each housing unit with a mailing address, and residents were asked to complete the questionnaire and return it to the Census Bureau in a postage-paid envelope.
The response rate was close to 50 percent.
The purpose of this research is to obtain information on why nonrespondents did not return the questionnaire by mail for Census 2000 in Puerto Rico.
This information will help develop strategies for improving the response rate for the 2010 Census.
.
B: Content and Data Quality Overview May 2002
C-42 For Census 2000, the public had five ways of providing census data.
These modes included mailing back a questionnaire, filling out a census short form on the Internet, picking up and returning a Be Counted form, completing a short form census interview via telephone questionnaire assistance, or completing a personal visit interview with an enumerator.
With this in mind, and the likelihood that the 2010 Census may offer additional options for response, studies in this category will document the hundred percent data item nonresponse by response mode.
Additionally, the data quality of each mode will be assessed.
This category includes a Content Reinterview Survey study that will measure response variance, and a Master Trace Sample study.
The latter will create a database containing a sample of census records with information pertaining to them from the entire census process.
Other research will evaluate multiple responses to the new race question.
What Will We Learn? The findings from these evaluations will answer a number of critical questions on our process to define content (i.e., what questions to ask) and the resulting quality of data for Census 2000.
These findings, in turn, can help us do a better job for the 2010 Census and the American Community Survey.
We will learn about the completeness of the data by calculating item imputation rates for several data items.
We also will look at hundred percent data item nonresponse by data collection mode.
We will assess responses to the new race question.
In particular, we will recontact a sample of households with responses of two or more races, and collect additional information, including an instruction to choose a single race category.
This study is needed to meet the data requirements of other agencies that use only single race categories, and for comparison to 1990 Census race data.
We also will gain knowledge about data quality in comparison to external benchmarks by matching and/or comparing census data to data collected by Census Bureau demographic surveys including the Current Population Survey, American Community Survey, and the Survey of Income and Program Participation.
The results of these matching and comparison studies will also help us to improve the design of future surveys and censuses.
Some of the reports that were developed in an expedited manner to inform the Executive Steering Committee for the Accuracy and Coverage Evaluation (ESCAP) decisions were sufficiently complete and informative to answer research questions from the planned evaluation reports.
One of these reports and its corresponding ESCAP report is noted in the following section of evaluation report descriptions.
To review the ESCAP report on the Internet, go to http://www.census.gov/ and search on "ESCAP."
May 2002
C-43 Content and Data Quality Evaluations (B.1) Analysis of the Imputation Process for 100 Percent Household Population Items To deal with missing and inconsistent data, three components will comprise the imputation process for Census 2000: assignment, allocation, and substitutions.
Rates for each of these components will be produced for the 100 percent characteristics and for the tenure item.
This analysis will document imputation rates and will serve as a supplement to other evaluations.
(B.2) Documentation of Characteristics and Data Quality by Response Type (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
Some of the hundred percent data item nonresponse aspects have been incorporated into the B.1 evaluation.
(B.3) Census Quality Survey to Evaluate Responses to the Census 2000 Question on Race Data by race from most federal surveys currently reflect a collection methodology of asking respondents to mark only one race category.
Users of the Census 2000 data on race will need to compare the race distribution from Census 2000 to these other sources.
The objective of the study is to produce a data file that will improve users' ability to make comparison between Census 2000 data on race, that allowed the reporting of one or more races, and data on race from other sources that allow single race reporting.
The primary goal is to improve comparisons of 1990 and Census 2000 race distributions at national and lower geographic levels.
Other goals are to facilitate comparisons between Census 2000 and Census Bureau surveys which instruct respondents to mark one race, and comparisons with data from the vital records system, which uses census data, to calculate such indicators as birth and death rates.
(B.4) Match Study of Accuracy and Coverage Evaluation to Census to Compare Consistency of Race and Hispanic Origin Responses (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation is relevant to this evaluation.
Refer to ESCAP I report, "A.C.E.
Consistency of Post-Stratification Variables" (report B-10).
(B.5) Content Reinterview Survey: Accuracy of Data for Selected Populations and Housing Characteristics as Measured by Reinterview The Content Reinterview Survey utilizes a test-retest methodology, whereby a sample of households designated to receive the census long form were reinterviewed shortly after they had been enumerated by the census.
These households are essentially asked the same questions posed on the long form.
Then the responses to the census and reinterview survey are compared.
This survey assesses response variance and error that results from data collection and capture operations.
(B.6) Master Trace Sample May 2002
C-44 While most evaluation studies will provide detailed information on specific Census 2000 operations, the Master Trace Sample database will provide information that can be used to study various operations, along with correlates of error across various systems, for a randomly selected group of census records.
This database will contain, but is not limited to: address list information (e.g., source of address), final values for questionnaire items along with their values at various stages of processing, and enumerator information (e.g., number of enumerator attempts before completing an interview and enumerator production rates).
This database also will contain information about the data capture system (from rekeying and reconciling a subset of Master Trace Sample questionnaire images), the Accuracy and Coverage Evaluation, and the Content Reinterview Survey.
This evaluation report will document the process of developing the Master Trace Sample database.
It will include information on the sources of data, limitations with the data, and some basic statistics from the database itself.
The majority of research and analysis that will be conducted using the Master Trace Sample database will not be done as part of this evaluation.
(B.7) Match Study of Current Population Survey to Census 2000 Using the results of a person-level match of responses to the Current Population Survey (CPS) and Census 2000, this study provides a data set about differences between the Census and Survey estimates of social, demographic, or economic characteristics.
Its strength is its ability to represent differences arising from non-sampling variation.
The study focuses on the difference between CPS and Census estimates of poverty and labor force status (which are measured officially by the CPS).
(B.8) Comparisons of Income, Poverty, and Unemployment Estimates Between Census 2000 and Three Census Demographic Surveys The purpose of this evaluation is to determine to what extent Census 2000 poverty, unemployment, and income estimates are comparable with estimates from the Current Population Survey, the American Community Survey, and the Survey of Income and Program Participation.
This study focuses on changes made to the Census 2000 questionnaire and forms processing systems that were designed to improve unemployment estimates.
This evaluation examines whether these changes brought the Census 2000 unemployment estimates (for states, and for various demographic and socio-economic groups) closer to the official Current Population Survey estimates than they were in 1990.
This analysis may be extended to compare data, definitions, and collection procedures with the Survey of Income and Program Participation.
(B.9) Housing Measures Compared to the American Housing Survey (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(B.10) Housing Measures Compared to the Residential Finance Survey (cancelled) May 2002
C-45 This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(B.11) American Community Survey Evaluation of Followup, Edits, and Imputations This evaluation will not be conducted because the available data cannot answer the specified questions for this study.
(B.12) Puerto Rico Race and Ethnicity For the first time, in Census 2000, households in Puerto Rico were asked to answer questions on race and ethnicity.
These were the same questions used on the stateside questionnaire.
This evaluation will explore how the census questions on race and Hispanic origin were answered by people living in Puerto Rico.
Specifically, it will investigate whether there are any generalizable patterns in how people responded to these questions according to age, level of education, level of income, and response mode.
In addition, it will look for patterns in responding to the Hispanic origin question by race and to the race question by Hispanic origin.
Finally, it will compare the patterns of responding to these questions with those of the general U.S. population.
This investigation will be conducted by preparing special data tables from the Census 2000 data for Puerto Rico.
The results will be used to help in the interpretation of the tabulated results on race and Hispanic origin for the Commonwealth.
(B.13) Puerto Rico Focus Groups on the Race and Ethnicity Questions The purpose of this research is to conduct a series of focus groups across Puerto Rico to learn more about how persons in Puerto Rico view these questions.
The results of the focus groups will be useful in preparing for the 2010 Census in Puerto Rico.
May 2002
C-46
This page intentionally left blank.
May 2002
C-47 C: Data Products Overview The focus of this evaluation is to determine the effects of disclosure prevention measures on Census 2000 data products.
We will examine the limitations and effects of data swapping and our confidentiality edit Â­ a combination of strategies used to prevent the disclosure of data that can be linked to an individual Â­ on our data products.
What Will We Learn? In studying our data swapping techniques, we will examine rates for different geographic levels and race groups and document any issues and problems that resulted from multiple responses to the race question.
Data Products Evaluations May 2002
C-48 (C.1) Effects of Disclosure Limitation on Data Utility in Census 2000 For Census 2000, the data swapping methods first used in 1990 were refined through better targeting and expanded to include sample data.
This evaluation examines variations in the effects of swapping due to: 1) a region's geographic structure, 2) a region's racial diversity, and 3) the number of dimensions used in the swapping.
(C.2) Usability Evaluation of User Interface With American FactFinder (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
Some focus groups were conducted and the results will be documented in a report, "Focus of Key Customer Segments."
Additionally, "Revisiting Standard Census Products in a New Environment," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(C.3) Data Products Strategy (cancelled) Information about the effectiveness of the data products strategy was rolled into evaluation C.2 in 2001, which recently was cancelled.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
D: Partnership and Marketing
May 2002
C-49 Overview During Census 2000, we used new methods to promote census awareness and increase public cooperation.
The Census 2000 Partnership and Marketing Program combined public awareness, promotion, and outreach activities to generate clear and consistent messages about the importance of participating in Census 2000.
The plan incorporated five components: direct mail pieces; media relations; promotions and special events (including Census in Schools); partnerships with businesses, non-governmental organizations, and government entities; and paid advertising.
The primary goal of our comprehensive marketing plan, including the first ever paid advertising campaign coupled with an expanded partnership program, was to increase the mailback response rate, especially among historically undercounted populations.
The advertising marketing strategy included messages delivered through print media, radio, television, and out-of-home media (billboards, bus shelters, mobile billboards).
The partnership program built partnerships with state, local, and tribal governments, community-based organizations, and the private sector.
Partners were asked to assist in three major areas: field data collection support, recruitment, and promotion.
In addition, a major school-based public information campaign was launched to inform parents and guardians about the census through their school-age children.
The planned evaluations for this category will assess the effectiveness of these activities as part of the integrated program components of the Census 2000 Partnership and Marketing Program.
What Will We Learn? These studies will help us understand how people's attitudes, knowledge, and behavior were affected by the Census 2000 Partnership and Marketing Program.
We will examine which elements of the paid advertising media were reported/recalled most often by hard-to-enumerate groups, and provide data for Hispanics and for five race categories: African-American, Asian, American Indian and Alaska Native, Hawaiian/Pacific Islanders, and White.
Specifically, we will look at what impact the marketing program had on the likelihood of returning a census form.
We also will compare these data to the 1990 Census, which had no paid advertising campaign.
The primary goals in studying the Partnership Program are to measure how well national and regional components accomplished their objectives in communicating a consistent census message of program initiatives and to determine which populations were best served by the program.
Our evaluation of the Census in Schools program will tell us about the effectiveness of census educational materials and whether teachers receiving census materials incorporated them in their curricula.
Overall, we will analyze how well the integrated strategy of the Census 2000 Partnership and Marketing Program met its two goals: 1) to increase the awareness of the census, and 2) to increase mailback response rates, especially among historically undercounted populations.
Partnership and Marketing Evaluations (D.1) Partnership and Marketing Program May 2002
C-50 The Census Bureau hired the National Opinion Research Center to conduct an assessment of the marketing and advertising campaign by fielding a survey before the campaign began, during the education phase of the campaign, and after the campaign had been launched.
From this evaluation, we will assess intended and self-reported response behavior and establish a baseline and pre- and post-census measures of awareness, knowledge, and attitudes of the census.
We will obtain the actual response behavior for respondents to our survey.
We statistically model what effect self-reported advertising exposure has on the likelihood of responding to the census.
This evaluation also explores the link between raised awareness, knowledge, attitudes, and response to the census.
Due to the integrated strategy of the Census 2000 Partnership and Marketing Program, the analysis will address components from the entire program, not individually for paid advertising and partnerships.
(D.2) Census in Schools/Teacher Customer Satisfaction Survey The Census Bureau hired Macro International to conduct a post-census survey of school teachers to assess the effectiveness of Census educational materials and whether teachers receiving census material incorporated them in their curricula.
(D.3.)
Survey of Partners/Partnership Evaluation We will assess the helpfulness of Census 2000 materials to partners, the types and value of services rendered, the specific partnership activities conducted, and the effectiveness of the program in reaching the hard-to-enumerate population.
We also will obtain from partners the organizational costs incurred to support and promote Census 2000.
The sample of partners will be selected using the Contact Profile and Usage Management System database.
Westat, an independent contractor, was hired to conduct this survey.
To improve response among the geographically dispersed and diverse partners in the Partnership Program, this evaluation uses as data collection modes a mailout/mailback questionnaire with a nonresponse followup telephone interview.
E: Special Places and Group Quarters Overview May 2002
C-51 The vast majority of U.S. residents live as families or individually in houses, apartments, mobile homes, or other places collectively known as "housing units."
However, there are millions of people in the United States who live in group situations such as college dormitories, nursing homes, convents, group homes, migrant worker dormitories, and emergency and transitional shelters.
Our evaluations will analyze the effectiveness of procedures to enumerate persons living in different types of group quarters.
The Census Bureau developed a specialized operation to enumerate selected service locations that served people without conventional housing.
The service-based enumeration operation was conducted from March 27 to March 29, 2000, at shelters, soup kitchens, mobile food vans, and targeted nonsheltered outdoor locations.
Some studies will focus on such things as enumeration at "service based locations" (shelters and food facilities for the homeless; outdoor locations where homeless people sleep).
Major evaluations are planned for two operations designed to enhance the address list of special places: the Special Place Facility Questionnaire and the Special Place Local Update of Census Addresses.
What Will We Learn? The findings from these evaluations will answer important questions on how effective enumeration procedures were in obtaining the count for group quarters.
We will compare the telephone and personal visit operations of the Facility Questionnaire.
The evaluations will include distributions of the group quarters populations by type of group quarters, counts of persons at group quarters on Census Day who indicated a usual home elsewhere, and comparison of the predicted group quarters universe from the Facility Questionnaire operation with the group quarters universe as enumerated.
Special Places and Group Quarters Evaluations (E.1.a) Special Place/Group Quarters Facility Questionnaire - Operational Analysis (cancelled) May 2002
C-52 This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(E.1.b) Facility Questionnaire - CATI and PV This evaluation used personal visit reinterviews at a sample of special places to assess the accuracy of the information collected from the Facility Questionnaire via computer assisted telephone interview or personal visit.
This evaluation will address how often changes occur in the special place type code and whether classification discrepancies differ by type of special place.
(E.2) Special Place Local Update of Census Addresses This evaluation focuses on local governments' participation in the Special Place Local Update of Census Addresses.
It will document changes to the address list along with operational issues that were encountered.
(E.3) Assess the Inventory Development Process for Service-Based Enumerations The purpose of this study is to evaluate the return on the efforts made to compile the inventory of Service-Based Enumerations places and addresses that were included in Census 2000.
The study will look at various sources that provided names and addresses and the results from enumeration to determine which sources proved to be more reliable (E.4) Decennial Frame of Group Quarters and Sources This study evaluates the content, coverage, and sources of the Decennial Frame of Group Quarters by comparing editions and records to independent sources, notably the contemporary Business Register.
This evaluation examines the feasibility and constraints to enrich or integrate these frames.
(E.5) Group Quarters Enumeration This study will document various aspects of the group quarters enumeration.
Some of the topics covered by this study include the total count of the group quarters population, the number of special places that were enumerated, and the number of group quarters that were enumerated.
Additionally, the numerical distribution of group quarters per special place and of residents per group quarters will be documented.
(E.6) Service-Based Enumeration The goal of the Service-Based Enumeration (SBE) was to enumerate people without housing who may have been missed in the traditional enumeration of housing units and group quarters.
A complete enumeration of shelters, soup kitchens, regularly scheduled mobile food vans and
May 2002
C-53 targeted nonsheltered outdoor locations was conducted in March 2000.
This evaluation will document data collection completeness, partial interviews, and whether the SBE unduplication process successfully identified individuals who were enumerated more than once.
May 2002
C-54
This page intentionally left blank.
May 2002
C-55 F: Address List Development Overview These evaluations cover a broad spectrum of activities, both internal and external, involved with building address files and the related geographic database, including field operations from which address information and related map updates are gathered.
The address list development category includes various evaluations of the Census Bureau's Master Address File (MAF), and the Topologically Integrated Geographic Encoding and Referencing (TIGER) database.
These include examination of the completeness and accuracy of address information in the MAF, as well as of the design of the MAF and DMAF.
An evaluation of the U.S. Postal Service's Delivery Sequence File used in the MAF building process is also planned.
A variety of census field and local/tribal partner operations will be evaluated to measure the impact of each operation on the MAF and the TIGER database.
These include, but are not limited to: Address Listing, Block Canvassing, Update/Leave, List/Enumerate, and multiple cycles of the Address List Review (also referred to as the Local Update of Census Addresses).
Combined, these field operations offer comprehensive address checks in rural and urban areas and are a primary source of address information used for MAF and TIGER database enhancement.
Additional evaluations focus on the geocoding accuracy of addresses in the census.
What Will We Learn? The findings from the address list development evaluations will provide insight into the most accurate methods for updating the MAF and the related TIGER database.
This includes understanding the individual contribution of each operation as it is implemented.
For each operation, we will look at the characteristics of addresses that were added, corrected, or flagged for deletion.
We also will look at the geographic impact of each operation (i.e., we will examine how changes to the MAF are distributed geographically).
Additionally, we will learn some things about the overall housing unit coverage in the census.
Finally we will learn more about quality and coverage by examining addresses that are on the full MAF, but were not included in the census for various reasons.
All of these evaluations will help inform continued MAF and TIGER database updating through the decade and also will provide insight for the 2010 Census and the American Community Survey.
Address List Development Evaluations May 2002
C-56 (F.1) Impact of the Delivery Sequence File Deliveries on the Master Address File Through Census 2000 Operations The Delivery Sequence File (DSF) is a file of addresses produced and maintained by the U.S. Postal Service.
The Census Bureau uses this file, along with the 1990 Census address list and other information, to create a permanent national address list called the Master Address File (MAF).
For Census 2000, the Census Bureau used the DSF as a primary source to enhance the initial MAF for mailout/mailback areas of the country.
Subsequent DSFs were used to update the address list through April of 2000, in order to maximize the inclusion of all existing addresses in the census.
This evaluation will assess the impact of each of the DSFs through Census 2000 operations by profiling the number and characteristics of housing units added to and deleted from the MAF following each delivery of the DSF. (F.2) Address Listing Operation and its Impact on the Master Address File For Census 2000, an Address Listing Operation was used in update/leave areas of the country to create the initial Master Address File (MAF) and provide a comprehensive update of the streets/roads and their names in the TIGER database.
In this operation, in areas where census questionnaires were subsequently hand delivered, census enumerators went door-to-door to identify the mailing address and physical location of every housing unit.
They also verified and updated the location and names of geographic features such as streets.
The Census Bureau used this procedure in order to create a file of good locatable addresses for Census Bureau field operations in Census 2000 as well as its future demographic surveys, including the American Community Survey.
This evaluation will assess the impact of the Census 2000 Address Listing Operation on the MAF by profiling the number and characteristics of housing units added to the MAF. (F.3) Local Update of Census Addresses 1998 The Local Update of Census Addresses (LUCA) operation (also known as Address List Review) for Census 2000 included a LUCA 98 operation that focused on mailout/ mailback areas.
For this operation, local and tribal government entities were provided a Census Bureau address list containing addresses derived from the Delivery Sequence File and the 1990 Address Control File.
The objective of the LUCA operations was to provide local entities the opportunity to review the Bureau's address information and related maps and then provide feedback in the form of 1) address adds, deletes and corrections and 2) street and street name adds, deletions, and corrections on the maps.
The Census Bureau compared the results to the block canvassing results in mailout/mailback areas, and all discrepancies were field verified.
After Census Bureau review of submissions, local and tribal entities were given the opportunity to review results and to appeal situations in which they believed the Master Address File (MAF) still was incomplete or incorrect.
This evaluation will assess the number and profile of housing unit adds to the MAF, the extent of geographic clustering of these adds, and the total number and profile of housing unit deletions and corrections.
May 2002
C-57 The evaluation also will include information documenting the participation rates of local and tribal governments and the proportion of addresses covered by these governments.
(F.4) Evaluation of the Census 2000 Master Address File Using Earlier Evaluation Data (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(F.5) Block Canvassing Operation For the 1990 Census, the Census Bureau conducted an operation called Precanvass to improve its address list for mailout/mailback areas.
For Census 2000, a similar operation, called Block Canvassing, was implemented.
As with the1990 Precanvass, this operation was conducted primarily in areas where city-style addresses are used for mail delivery; however, for Census 2000, the Block Canvassing Operation covered a larger geographic area than did the 1990 Precanvass Operation, and the scope of the operation was expanded to include map (i.e. TIGER database) updates.
The objective of this evaluation is to determine the overall effect of the Block Canvassing Operation on the Master Address File (MAF) by measuring the number and characteristics of housing unit adds, deletes, and corrections to the MAF. (F.6) Local Update of Census Addresses 1999 The Local Update of Census Addresses (LUCA) operation (also known as Address List Review) for Census 2000 included a LUCA 99 operation for Update/Leave areas.
For LUCA 99, local and tribal government entities were provided with census housing unit block counts that were created using addresses obtained from the Address Listing Operation.
Participating entities were asked to review the counts and provide feedback when they believed the number of housing unit addresses for the block should have been higher or lower.
Participating governments could challenge block counts, but could not provide specific housing unit adds, corrections, or deletes.
Blocks that were challenged were sent to LUCA 99 Field Verification for relisting, then returned to participating governments for another review.
This evaluation will document the participation rates of those tribal and local governments that were eligible to participate, the proportion of addresses covered by those governments, the number of blocks that were challenged and went to LUCA 99 Field Verification, and the extent to which changes occurred during the field verification.
(F.7) Criteria for the Initial Decennial Master Address File Delivery (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(F.8) The Decennial Master Address File Update Rules (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
May 2002
C-58 (F.9) New Construction Adds (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
Some of the planned research for this study will be evident in evaluation I.4, Coverage Improvement Followup.
(F.10) Update/Leave The Update/Leave operation was conducted in areas where mail delivery of questionnaires was problematic.
Field staff dependently canvassed their assigned area, updated the address list and map, and distributed a questionnaire to each housing unit.
This evaluation will document address corrections, added units, and units flagged for deletion during the operation.
We also will study problem referral forms completed by enumerators for difficult listing situations (e.g., unable to obtain access, gate blocked, road washed away, no trespassing signs), to see how well these situations were followed through and how they might have contributed to coverage errors.
(F.11) Urban Update/Leave The Urban Update/Leave was an operation that targeted whole census blocks and was conducted in areas where the Census Bureau was not confident that the addressed questionnaires will be delivered to the corresponding housing units.
For Census 2000, eight of the 12 Regional Census Centers identified blocks for this operation.
The Charlotte, Kansas City, Los Angeles, and New York Regional Census Centers decided to use other special enumeration methodologies in lieu of Urban Update/Leave.
This evaluation will assess the number of addresses added, deleted, corrected, and moved as a result of Urban Update/Leave.
It will profile the housing unit addresses as follows: type of address, single/multi-unit; drop/nondrop delivery.
Delivery Sequence File match/nonmatch.
It will also look at the addresses in terms of occupancy status and will describe the persons in Urban Update/Leave addresses by sex, age, Hispanic origin, and race.
(F.12) Update/Enumerate Update/Enumerate is similar to Update/Leave, except that interviewers enumerated the unit at the time of their visit rather than leaving a questionnaire to be completed and mailed back.
The operation was conducted in communities with special enumeration needs and where most housing units may not have house numbers and street name addresses.
These areas include some selected American Indian Reservations and the Colonias.
Update/Enumerate was implemented in resort areas with high concentrations of seasonally vacant housing units.
Most Update/Enumerate areas were drawn from address listed areas, but some came from block canvass areas.
This evaluation will document the number and characteristics of housing units added, deleted, corrected, and moved in Update/Enumerate areas.
(F.13) List/Enumerate May 2002
C-59 List/Enumerate was an all-in-one operation conducted in sparsely populated areas of the country.
The address list was created and the housing units enumerated concurrently.
The main objectives of this evaluation will be to profile all addresses produced by the List/Enumerate operation, as well as to specifically profile the List/Enumerate addresses that matched to the Delivery Sequence File.
(F.14) Overall Master Address File Building Process for Housing Units (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
Objectives of this evaluation will be met with the Address List Development topic report, which will synthesize results from evaluations, experiments, and include some new analysis across all of the major sources and operations that contributed to the Master Address File in Census 2000.
(F.15) Quality of the Geocodes Associated With Census Addresses The objective of this evaluation is to measure the quality of residential address geocoding in Census 2000 and to identify the source of the geocode (i.e., the TIGER database, one of the several field operations, LUCA/New Construction participants, etc.).
(F.16) Block Splitting Operation for Tabulation Purposes Block Split operations are conducted by the Census Bureau to provide for tabulation of data where governmental unit and statistical area boundaries do not conform to collection block boundaries.
This evaluation will measure the accuracy of block splitting operations for tabulation purposes.
May 2002
C-60
This page intentionally left blank.
G: Field Recruiting and Management May 2002
C-61 Overview Prompted by the difficulties in recruiting applicants and high turnover of employees in the 1990 Census, the Census Bureau redesigned its recruitment, staffing, and compensation programs for Census 2000.
Several new programs were developed to address the 1990 issues and to help the Census Bureau successfully recruit several million applicants, hire several hundred thousand employees, and retain this staff through the decennial census.
Some of these programs included frontloading, higher pay rates, and paid advertising.
What Will We Learn? The purpose of this evaluation is to study the effects of these new program activities upon recruitment, staffing, and retention.
A contractor, for example, determined that the 1990 District Office (now Local Census Office) pay rates were not adequately set to attract and retain staff when compared to local economic conditions of that area.
The methodology to set the Census 2000 pay rates, based on this knowledge, was revised and set to a derivative of the local prevailing pay rate.
The effectiveness of this higher pay rate will be evaluated, as well as other recruitment and hiring programs (such as frontloading and paid advertising).
Field Recruiting and Management Evaluations
May 2002
C-62 (G.1) Census 2000 Staffing Programs This evaluation examines the effectiveness of the Census 2000 hiring programs during Nonresponse Followup (NRFU).
Study questions will focus upon the effectiveness of the higher pay rate program, frontloading, paid advertising, and other areas.
Some of the questions are: 1) was the Census Bureau able to adequately hire and attract staff to execute NRFU, Accuracy and Coverage Evaluation, and other various field operations; 2) were the pay rates effective in attracting and retaining staff needed for Census 2000 NRFU; and 3) did recruiting activities provide an adequate supply of applicants and replacements.
A portion of this study will examine the effectiveness of the higher pay rates on productivity and evaluate the pay model as a predictor of local economic conditions.
(G.2) Operation Control System This evaluation has been moved to Evaluation Category R, Automation of Census Processes; see R.2.a, Operations Control System 2000, System Requirements Study for its description.
H: Field Operations Overview May 2002
C-63 This category includes studies of various field operations and strategies whose goals were to curb questionnaire delivery and enumeration problems, and obtain census data from individuals who did not respond to the census by a specified date.
For example, the Nonresponse Followup operation consisted of sending an enumerator to collect census data from every address from which no mail, telephone, or Internet response was received.
Evaluations in this category will analyze whether field operations were conducted as planned and will assess their effectiveness.
Additionally, operational results will be documented for each LCO for historical purposes.
Analyses in this category also will examine our efforts to count those categorized as hard-toenumerate.
Our targeting methodologies consisted of 1990 person and housing unit census data that are indicators of nonresponse and the potential to be undercounted.
This information assisted the Regional Census Centers in determining the placement of Questionnaire Assistance Centers and Be Counted Forms.
The information also assisted participants of our partnership program.
Studies in this category will evaluate how successful our targeting methodologies were along with the usage of Questionnaire Assistance Centers.
In addition, we will evaluate our targeted enumeration methods such as blitz enumeration (use of a group of enumerators to conduct enumeration in a compressed time frame), team enumeration (two enumerators working together where safety is a concern), and the use of local facilitators (long-time neighborhood residents or church leaders who assist the enumerator in gaining entry to the neighborhood).
Because some respondents were able to provide data without a census identification number (e.g., Be Counted and Telephone Questionnaire Assistance), it was possible that respondents submitted addresses that were not on our Master Address File.
We conducted a field verification of these types of addresses.
If an enumerator verified that the address was a valid housing unit, then it was added to the Decennial Master Address File.
We also will conduct an evaluation of the effectiveness of this operation.
What Will We Learn? The results of these evaluations will give us an indication of how successful we were at obtaining data from nonrespondents including those living in areas where we employed special enumeration methodologies, and how to better plan these types of operations for future censuses.
The evaluation of Nonresponse Followup will report proxy rates, the number of partial interviews, vacancy rates, and the number of units enumerated during final attempt procedures, which will help us to assess whether the operation was conducted as planned.
Other analyses will provide information about the quality of our enumerator training program, the utility of our targeting methods, and a profile of Local Census Offices which will contain various descriptive statistics.
May 2002
C-64 Field Operations Evaluations (H.1) Use of 1990 Data for Census 2000 Planning (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
"Using the Planning Data Base to Plan Data Collection for Census 2000," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(H.2) Operational Analysis of Field Verification Operation for Non-ID Housing Units Non-ID questionnaires are those from the Be Counted and Telephone Questionnaire Assistance operations or questionnaires for which an enumerator was not able to verify that the address existed.
During field verification, enumerators visited the location of these non-ID housing units and verified their existence on the ground before they were added to the Master Address File (MAF)/Decennial Master Address File (DMAF).
For Census 2000, non-ID questionnaires that were geocoded to a census block, but did not match to an address already in the MAF were assigned for field verification.
This operational analysis will attempt to answer questions such as how many units were added to the MAF/DMAF after verification and if operational problems were encountered during the implementation of field verification.
(H.3) Local Census Office Delivery of Census 2000 Mailout Questionnaires Returned by U.S. Postal Service With Undeliverable as Addressed Designation (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(H.4) Questionnaire Assistance Centers for Census 2000 The Census Bureau provided walk-in assistance centers where respondents received assistance with completing their questionnaire.
Language assistance guides were available in over 40 different languages, along with Be Counted forms that were available in English and five other languages.
This study will document various aspects of the Questionnaire Assistance Centers (QACs) such as location, employees, and types of assistance.
In addition, the frequency of use of the QACs will be analyzed.
(H.5) Nonresponse Followup for Census 2000 This operation was conducted for all housing units in the mailout/mailback and update/leave areas for which the Census Bureau did not check in a questionnaire by April 11, 2000.
During Nonresponse Followup (NRFU), enumerators visited each nonresponding unit to determine the occupancy status of the unit on Census Day and to collect the appropriate data (i.e., long form or short form) for the household members.
The objective of this analysis is to document various aspects of the NRFU operations.
Some of the topics covered in this study include determination of NRFU workloads, identification of the demographics of those enumerated in NRFU, and documentation of the number of NRFU Enumerator Questionnaires that were partial interviews, refusals, completed via proxy respondents, or completed during final attempt procedures.
The May 2002
C-65 percent of NRFU units classified as occupied, vacant, or delete will be documented.
Additionally, this evaluation will determine when each Local Census Office (LCO) started and completed their NRFU operation and the cost of the operation.
(H.6) Operational Analysis of Non-Type of Enumeration Area Tool Kit Methods Tool kit methods were special enumeration procedures (e.g., blitz enumeration, and the use of local facilitators) available for improving cooperation and enumeration in hard-to-enumerate areas.
For this evaluation, the Census Bureau will assess the tool kit methods used, where they were used, and the effectiveness and feasibility of the tool kit methods.
(H.7) Nonresponse Followup Enumerator Training During Census 2000, we hired over 500,000 people to fill temporary positions.
The largest number of these workers were hired for the Nonresponse Followup (NRFU) operation.
Adequate employee training was critical to the success of NRFU.
The overall objective of this evaluation is to examine the quality of the NRFU enumerator training program as well as the enumerator's state of preparedness following training.
(H.8) Operational Analysis of Enumeration of Puerto Rico Census 2000 was the first time that an Update/Leave mailback methodology was used to conduct the enumeration in Puerto Rico.
This evaluation will determine how many addresses were encompassed by this enumeration methodology, a profile of the addresses, and what operational problems were encountered in the field as a result of address list compilation and processing procedures.
This study also will make comparisons to stateside Update/Leave data.
(H.9) Local Census Office Profile This operational summary will provide descriptive statistics at the Local Census Office (LCO) level for many census operations.
For example, total housing units, average household size, and mail return rate will be among the statistics reported for each LCO. (H.10) Date of Reference for Respondents of Census 2000 The Census 2000 questionnaire stated that the respondent should report age as of April 1, 2000.
This study will document the average date of reference used by census respondents and the average date of reference by method of enumeration.
This study also will document various types of discrepancies between date of birth and reported age.
May 2002
C-66 I: Coverage Improvement Overview The coverage improvement evaluations examine various Census 2000 operations that are intended to improve the coverage of both housing units and people in the census.
Following the mailback efforts to complete the census, a series of operations were conducted to ensure that people were counted at their correct Census Day address, to confirm the status of housing units that were deleted or enumerated as vacant, and to ensure the inclusion of all persons in a household when the returned form showed discrepancies in the number of persons enumerated.
What Will We Learn? From these evaluations we will learn about the effectiveness of these various operations as they attempt to improve census coverage.
From the Nonresponse Followup operation, we will examine the potential coverage gain from identifying movers and checking to see if they were counted at their Census Day address.
We will also analyze the situations where entire households were identified as having a "usual home elsewhere."
For the Coverage Improvement Followup, we will examine the person and housing unit coverage gains from this operation, which determined the Census Day status of certain types of housing units (most of which were identified as deletes or coded as vacants in earlier census operations).
The evaluation of the Coverage Edit Followup will measure coverage gains from this operation, which consisted of contacting households whose completed forms showed discrepancies regarding the number of persons enumerated, or whose completed form indicated there were more than six persons in that household.
Furthermore, we will evaluate the coverage questions on the enumerator questionnaire to determine how well enumerators asked these questions and used the answers to obtain an accurate household roster.
Coverage Improvement Evaluations May 2002
C-67 (I.1) Coverage Edit Followup for Census 2000 The Coverage Edit Followup (CEFU) was designed to increase within household coverage and improve data quality in two ways.
A standard questionnaire only has room for six persons, so CEFU was used to collect data on additional persons in large households.
Second, it resolved discrepancies on mail return forms between the reported household size and the actual number of persons for which data were recorded on the census form.
An attempt was made to resolve all households that failed edits for these situations by using a Computer Assisted Telephone Interview.
This analysis will document the workload, operational aspects, and coverage gains from conducting this operation.
(I.2) Nonresponse Followup Whole Household Usual Home Elsewhere Probe During the Nonresponse Followup (NRFU), List/Enumerate, and Update/Enumerate operations, enumerators asked respondents whether their address was a seasonal or vacation home and if the whole household had another place where they lived most of the time.
When respondents indicated they had a usual home elsewhere on Census Day, enumerators recorded census information about this on a blank Simplified Enumerator Questionnaire (SEQ - a version of the mail return questionnaire that is easier to use for personal visit enumeration) and enumerated the current address as a vacant unit or obtained information about the people living there on Census Day.
This evaluation examines how often SEQs were completed as Whole Household Usual Home Elsewhere (WHUHE); how many of these addresses were matched to an address on the Decennial Master Address File (DMAF); how often addresses could neither be matched to the DMAF or geocoded; for matched addresses, how often was the WHUHE household already included on the census form for their ususal place of residence; and how often did we find a different household on the census questionnaire.
(I.3) Nonresponse Followup Mover Probe In Census 2000, in-movers (households that moved there after Census Day) were identified during the Nonresponse Followup (NRFU), List/Enumerate, and Update/Enumerate operations and were asked if they were enumerated at their Census Day address.
If a respondent did not recall completing a census form at their Census Day address, the enumerator completed a questionnaire for the in-mover household using their Census Day address.
This evaluation looks at how many of these cases occurred, and how many persons were added to the census as a result of this procedure.
(I.4) Coverage Improvement Followup The Coverage Improvement Followup (CIFU) universe consisted of units classified as vacant or deleted in NRFU, adds from the new construction operation, late adds from Update/Leave, blank mail returns, and lost mail returns, if any.
During CIFU, enumerators visited these units to verify the Census Day status and collect person and housing unit data as appropriate.
This evaluation will document the person and housing unit coverage gain from conducting the CIFU, including the number of units that changed status from vacant to occupied or from delete to either vacant or occupied.
This study also will examine the characteristics of persons and housing units added as a result of the CIFU, start/finish dates, and the cost of the operation.
May 2002
C-68 (I.5) Coverage Gain from Coverage Questions on Enumerator Completed Questionnaire In 1990, enumerators began their interview with an explanation of who should be included as residents of the household.
This procedure was changed for Census 2000.
Now, enumerators begin by asking how many people were living or staying in the housing unit on Census Day.
After collecting appropriate person and housing unit data, the enumerator asked two coverage questions.
The first asked about typical situations in which persons who should be included as residents tend to be missed Â­ babies, foster children, persons away on business or vacation, roomers or housemates, and temporary residents with no other home.
If someone had been missed, then he or she was added to the form and their census information was collected.
The second question asked about typical situations in which persons who should not be included as residents tend to be included as such Â­ persons away at college, in the armed forces, in a nursing home, or in a correctional facility.
If someone was included on the form but should have been counted elsewhere, then the enumerator deleted them from the form by marking the cancel box under their name.
The purpose of this analysis is to study the effectiveness of the new coverage questions in the identification of persons who would have otherwise been missed or included in error.
(I.6) Coverage, Rostering Methods and Household Composition: A Comparative Study of the Current Population Survey and Census 2000 (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
May 2002
C-69
This page intentionally left blank.
May 2002
C-70 J: Ethnographic Studies Overview These evaluations will study certain aspects of coverage for various populations and attempt to identify areas where methods of collecting census data for these populations can be improved.
One study in this category will apply social network field and analysis methods to evaluate census coverage and processes.
We also will conduct ethnographic research on mobile populations and Colonias Â­ areas lacking basic infrastructure and services along the border between the United States and Mexico.
What Will We Learn? Study results will help us determine whether individuals can be better identified from their position in social networks (based on their interactions and transactions with others) than by comparing sets of address and person records.
We will also learn how to improve procedures to enumerate mobile populations by tracing Census Day travel routes or stopover sites for a sample of such persons and determining undercounts or multiple enumerations of them in the census.
We also will learn how to overcome barriers to enumerating Colonias in future censuses.
Ethnographic Studies May 2002
C-71 (J.1) Coverage, Rostering Methods and Household Composition: A Comparative Study of the Current Population Survey and Census 2000 This evaluation was reclassified under the Coverage Improvement category as evaluation I.6, which was recently cancelled.
(J.2) Ethnographic Social Network Tracing This study will use ethnographic and social network methods to study the following five questions.
1) What interactions in social networks influence and explain or determine the duration of individuals' stays in domiciles (i.e., households, institutions, or other places where people sleep) and their residential mobility? 2) How much more likely are people who change domicile once or more in 6 months to be omitted or erroneously enumerated in Census 2000 (and in contemporary demographic surveys) than people who remain residentially stable over a 6month period? 3) What characteristics (of people, their networks, mobility, housing, household, occupational, or other social or economic factors) are closely associated with omission in the census? 4) Can people be more reliably identified (and re-identified) from their position in social networks and from their interactions with others, than by comparing sets of address and person records? 5) How well do Census Bureau categories fit with the socially represented characteristics that people use to form interacting social networks? (J.3) Comparative Ethnographic Research on Mobile Populations In this study, a sample of selected mobile people will be traced to identify their Census Day travel routes or stopover sites.
The information will be matched and reconciled with census results.
Coverage errors found in the census will be analyzed to develop recommendations for improving procedures.
(J.4) Colonias on the U.S./Mexico Border: Barriers to Enumeration in Census 2000 Colonias are unincorporated, generally low income residential subdivisions lacking basic infrastructure and services (e.g., paved roads and public water systems) along the border between the U.S. and Mexico.
In order to develop appropriate enumeration procedures and effective outreach and promotion programs for Colonias, it is necessary to better understand the unique situations and issues associated with conducting the census or other Census Bureau surveys in these areas.
This research will examine the potential barriers to census enumeration in Colonias in the context of Census 2000 through participant observation, in-depth interviews, and focus groups with selected Colonia residents.
Based on previous research, topics of particular interest include irregular housing, concerns regarding confidentiality, complex household structure, knowledge of English, and literacy.
K: Data Capture
May 2002
C-72 Overview The Data Capture System for Census 2000 (DCS 2000) processed more than 120 million census forms by creating a digital image of each page and interpreting the entries on each image using Optical Mark Recognition (OMR), Optical Character Recognition (OCR), or keying.
These evaluations are designed to assess components of DCS 2000, the Data Capture Audit Resolution (DCAR) process, and to measure the impact of the data capture system on data quality and on subsequent data coding operations.
What Will We Learn? Findings from these evaluations will determine the level of accuracy at which the data capture system performed.
Detailed information about the system will be collected, ranging from the number of forms processed by form type, date, and processing office, to measuring the accuracy of each of the three capture modes - OMR, OCR, and Key From Image.
Operational problems and their resolution will be documented.
Evaluation of the DCAR process will examine the system's ability to identify and resolve capture problems stemming from problems with response entries.
The impact of data capture errors on our ability to correctly assign industry and occupation codes will also be assessed.
Data Capture Evaluations (K.1.a) Data Capture Audit Resolution Process May 2002
C-73 This evaluation documents the results of Data Capture Audit Resolution by failure reason, form type, and Data Capture Center.
Using these same categories, it also will document the number and types of changes that can be made by Audit Review clerks and the results of the Audit Count review.
(K.1.b) Quality of the Data Capture System and the Impact of Questionnaire Capture and Processing on Data Quality This evaluation examines how the data capture system affected data quality and whether the rules for determining where cases are routed (e.g., to key from image) were set appropriately.
In addition, this evaluation will document and compare the data quality of each data capture method for every field on the questionnaire, as well as by form type, Data Capture Center, and racial and ethnic categories.
(K.1.c) Analysis of Data Capture System 2000 Keying Operations (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(K.1.d) Synthesis of Results from K.1.a, K.1.b, and K.1.c This evaluation will not be conducted.
Results from evaluations K.1.a, K.1.b, and K.1.c will be included in a topic report addressing key findings for all data capture evaluations.
(K.2) Analysis of the Interaction Between Aspects of Questionnaire Design, Printing, and Completeness With Data Capture (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census.
Significant aspects of this study will be addressed in evaluations K.1.a and K.1.b.
(K.3) Impact of Data Capture Errors on Autocoding, Clerical Coding and Autocoding Referrals in Industry and Occupation Coding The information provided by respondents to the industry and occupation questions on the census form were assigned (coded) to a standard set of categories.
This evaluation examines how data capture errors affected the ability of the autocoding system and clerical coders to assign correct Industry and Occupation codes.
(K.4) Performance of the Data Capture System 2000 (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
L: Processing Systems Overview
May 2002
C-74 Once census data from all sources were captured by the Data Capture System 2000, they were normalized (put in a standard format, regardless of input source) and stored in a file known as the Decennial Response File, stage 1 (DRF1).
Several processes then were applied before the data were used to produce official census counts and tabulations.
One process was applied to link multiple questionnaires that were used to enumerate that same household.
For example, a large family could have a mail return form with data on six members of the household and an additional followup Computer Assisted Telephone Interview (CATI) with data on the rest of the household.
Under these circumstances, CATI person records are appended to the original mail return person records.
Another process was used for situations where multiple questionnaires involving different households were received for the same address.
For example, one form could be for a household that moved out near Census Day, and the other form could be for the household that then moved in.
A computer program known as the Primary Selection Algorithm (PSA) then was used to decide which person and housing unit data should be used for census tabulations.
The input into PSA is the DRF1, with the resulting file being the Decennial Response File, stage 2 (DRF2).
Following all these processes, the DRF2 was merged with key elements of the Decennial Master Address File (DMAF) to create the 100 Percent Census Unedited File (HCUF), which contains the response data (i.e., the 100 percent questions from both the short and long form census questionnaires) selected by PSA processing to represent a household in the census.
The Sample Census Unedited File (SCUF) contains the unedited responses for households with sample (long form) data.
A variety of post-census activities were needed to prepare the data from the original responses to releasing the official counts and tabulations.
These activities include editing and imputation of the HCUF and SCUF to create the 100 Percent Census Edited File (HCEF) and the Sample Census Edited File (SCEF) respectively, coding of write-in response items (such as race, language, industry and occupation, and place of work/migration), conversion to tabulation geography, tabulation recoding, and applying disclosure avoidance techniques.
The Beta Site was a software testing site for Bureau of the Census application developers and is used as an integration center for Regional Census Centers (RCC) and Local Census Offices (LCO) systems, a testing center for all systems, and a support center for RCC, LCO, and the National Processing Center systems.
We will examine the effectiveness of this software testing site.
May 2002
C-75 What Will We Learn? Analysis of a reinterview of multiple questionnaire addresses will determine if the PSA methodology and rules for resolving these cases accurately identified the Census Day household members.
The evaluation of the DRF creation and processes will examine how well multiple forms for the same household were linked.
Analysis of CUF creation will document the number of times each specific DMAF/DRF rule was applied.
The Beta Site analysis will include information on whether the data collection systems were successfully integrated, and the benefits of the software testing and release process.
May 2002
C-76 Processing Systems Evaluations (L.1) Invalid Return Detection This evaluation was not conducted because the operation was not necessary in Census 2000.
(L.2) Decennial Response File Stage 2 Linking and Setting of Expected Household Population This evaluation will document how frequently census forms were linked during the Decennial Response File processing and the types of linkages that were constructed.
It will also assess the accuracy of the automated process for setting the expected household size and its effects on the census population.
(L.3.a) Analysis of Primary Selection Algorithm Results (Operational Assessment) The objective of this evaluation is to document the effects of using the Primary Selection Algorithm in resolving situations when multiple household questionnaires were received for the same address.
(L.3.b) Resolution of Multiple Census Returns Using Reinterview The objective of this evaluation is to determine the accuracy of Primary Selection Algorithm rules for determining the Census Day residents for an address.
Comparisons were made between final Census 2000 data and data that were collected using a reinterview of a sample of addresses where the Primary Selection Algorithm was applied.
(L.4) Census Unedited File Creation This evaluation documents the results of the process of determining the final housing unit inventory.
The final housing unit inventory for the census was determined during the process of creating the Census Unedited File.
The final housing unit inventory was created by merging information on the processed Decennial Response File with the information on the Decennial Master Address File.
(L.5) Beta Site This evaluation will answer questions about how well the Beta Site integrated the software systems supporting Census 2000 and its overall utility for software testing and release.
May 2002
C-77
This page intentionally left blank.
May 2002
C-78 M: Quality Assurance Evaluations Overview Census 2000 involved more than 20 major field operations and, at its peak, more than 500,000 temporary workers.
Managing the quality of the deliverables produced by this large, decentralized, and transient workforce was a major challenge for the Census Bureau.
The quality assurance (QA) programs were designed to minimize significant performance errors, to prevent the clustering of significant performance errors, and to promote continuous improvement.
What Will We Learn? The first evaluation will determine the effectiveness of the QA programs used in the address list development and enumeration operations and will determine if different QA approaches should be explored for the next census.
For the second study, the effectiveness of variables that were used to detect discrepancies will be measured, and appropriate variables will be added and/or deleted from the detection process.
May 2002
C-79 Quality Assurance Evaluations (M.1) Evaluation of the Census 2000 Quality Assurance Philosophy and Approach Used for the Address List Development and Enumeration Operations The study will determine the effectiveness of the quality assurance philosophy and activities used to manage the quality of the deliverables produced in the address list development and enumeration operations.
This study will document operational experiences with this approach, measure quality levels achieved, and determine if other approaches should be explored for the 2010 Census.
(M.2) Effectiveness of Existing Variables in the Model Used to Detect Discrepancies During Reinterview, and the Identification of New Variables The reinterview program was a quality assurance measure whose major objective was to detect enumerators whose work indicated discrepancies.
This evaluation examines variables used in this model to determine if they were effective in detecting discrepancies; whether other variables should be added to the model; and to provide suggestions on other ways to improve this program.
May 2002
C-80 N: Accuracy and Coverage Evaluation Survey Operations Overview The Census Bureau conducted the Accuracy and Coverage Evaluation (A.C.E.), a nationwide sample survey, to determine the number of people and housing units missed or incorrectly counted in the census.
The basic approach was to independently relist a sample of blocks, reenumerate them during the A.C.E. survey, and then compare the results to the census data for the same blocks.
The Census Bureau may use the results of the A.C.E. to correct the census counts obtained through the preceding enumeration procedures.
The studies in this category will measure how well the Census Bureau carried out different components of the A.C.E.
For instance, analysis projects and evaluations will be conducted that measure the completeness of the housing unit lists used for A.C.E. interviewing, the quality of the A.C.E. person interviewing process, and the accuracy of the procedures used to match persons counted during the A.C.E. interview to those that were enumerated in the census.
The success of each A.C.E. component affects the quality of the final estimates.
What Will We Learn? The results of these A.C.E. analysis projects and evaluations will help the Census Bureau to document this coverage measurement operation and improve its procedures.
For example, we will determine how well we detect discrepant results, while also looking at their effect on the A.C.E.
These operational analyses and evaluations will document the A.C.E. process and give the Census Bureau greater insight into what causes error in the measurement of coverage error.
Moreover, matching errors may add to errors in the estimates of census coverage.
One evaluation in this category will examine a subsample of rematched A.C.E. blocks to measure matching errors.
We also will measure the effect of matching error on Dual System Estimates and undercount rates.
The evaluations in this category will help the Census Bureau to identify operational causes of error in measuring coverage and will help to minimize them when planning future censuses.
Many evaluations in this category that were planned for the A.C.E. were no longer need when the decision was made not to adjust the Census 2000 population counts.
It was determined that some of the reports that were developed in an expedited manner to inform the Executive Steering Committee for A.C.E. (ESCAP) decisions were sufficiently complete and informative to answer research questions from the planned evaluation reports.
Five of these reports and their corresponding ESCAP reports are noted in the following section of evaluation report descriptions.
To review the ESCAP reports on the Internet, go to http://www.census.gov/ and search on "ESCAP."
May 2002
C-81
May 2002
C-82 A.C.E.
Survey Operations Evaluations (N.1) Contamination of Census Data Collected in A.C.E.
Blocks This evaluation examines whether census and A.C.E. operations were kept operationally independent (a key requirement for avoiding bias in the dual-system estimates of coverage error) by comparing census results in A.C.E. and non-A.C.E. clusters and through debriefing of field staff.
(N.2) Analysis of Listing Future Construction and Multi-Units in Special Places (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.3) Analysis of Relisted Blocks (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.4) Analysis of Blocks With No Housing Unit Matching (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.5) Analysis of Blocks Sent Directly for Housing Unit Followup (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.6) Analysis of Person Interview With Unresolved Housing Unit Status (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.7) Analysis on the Effects of Census Questionnaire Data Capture in A.C.E. (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.8) Analysis of the Census Residence Questions Used in A.C.E. (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation ( ESCAP ) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP report, "Evaluation Results for Movers and Nonresidents in the Census 2000 Accuracy and Coverage Evaluation" (report B-16).
(N.9) Analysis of the Person Interview Process (cancelled) May 2002
C-83 This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP I report, A.C.E.
Person Interviewing Results ( report B-5).
Additionally, "Automating the Census 2000 A.C.E.
Field Operations" and "Results of Quality Assurance on the Person Interview Operation of the A.C.E. of Census 2000" provide preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of these papers, contact the Census Bureau on (301) 457-4218.
(N.10) Discrepant Results in A.C.E.
This evaluation examines how well the quality assurance process identified interviewers who entered discrepant data in the A.C.E. interview and the impact of undetected discrepant data on A.C.E. estimates.
(N.11) Extended Roster Analysis (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.12) Matching Stages Analysis (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP I report, "A.C.E.
Person Matching and Followup Results" (report B-6).
Additionally, "Results of Quality Assurance on the A.C.E.
Matching Operations," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(N.13) Analysis of Unresolved Codes in Person Matching (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP I report, "A.C.E.
Variance Estimates by Size of Geographic Area" (report B-11).
(N.14) Evaluation of Matching A potential source of error in the persons as missed or erroneously relative error associated with the System Estimates.
Error coverage estimates is the matching operation used to classify enumerated in the census.
This evaluation will determine the matching operation and how matching error affects the Dual
(N.15) Outlier Analysis in the 2000 A.C.E. (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
May 2002
C-84 (N.16) Impact of Targeted Extended This evaluation will not be conducted.
refined and priorities reassessed due to aspects of this study will be addressed Search (cancelled) In early 2002, the Census 2000 Evaluation Program was resource constraints at the Census Bureau.
Significant in evaluation N.17.
(N.17) Targeted Extended Search Block Cluster Analysis In 1990, the search area for matching was extended to surrounding blocks for all clusters.
In 2000, this was only done for clusters deemed most likely to benefit from this additional searching.
This report will document overall targeted extended search results and identify characteristics that may be related to matches and correct enumerations found in surrounding blocks due to geocoding error.
(N.18) Effect of Late Census Data on Final Estimates (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Effect of Excluding Reinstated Census People from the A.C.E Person Process."
(N.19) Field Operations and Instruments for A.C.E.
This analysis provides an overall assessment of the quality of housing unit and person coverage in A.C.E. operations.
Some of the topics addressed in the analysis are quality of A.C.E. listing, effect of housing unit followup interviewing on the enhanced list, effectiveness of housing unit and person followup quality assurance, and noninterview rates.
(N.20) Group Quarters Analysis (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(N.21) Analysis of Mobile Homes (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
May 2002
C-85
This page intentionally left blank.
May 2002
C-86 O: Coverage Evaluations of the Census and of the Accuracy and Coverage Evaluation Survey Overview The studies in this category include a group evaluating A.C.E. coverage and a group evaluating census coverage.
These studies will identify person and housing unit characteristics that are related to being missed or erroneously enumerated.
Analysis in this area will also study the quality of data from proxy respondents, and the frequency and patterns of geocoding error.
Furthermore, census counts and dual system estimates will be compared to demographic benchmarks to evaluate accuracy and completeness.
What Will We Learn? Results from these evaluations will allow us to determine how complete our Master Address File was for Census 2000.
Net coverage rates of housing units will be computed at the national and subnational levels along with gross omission and erroneous enumeration rates.
Other studies will explain factors that contribute to housing unit coverage error.
For example, we will learn whether type of address (city style versus noncity style) had an effect on housing unit coverage.
In addition, there will be a study of housing unit duplication, to identify characteristics of duplicate units and their operational source.
Similarly, we will identify factors that contribute to person coverage error.
We will acquire knowledge about erroneous enumerations by determining which demographic, housing unit type, and type of enumeration variables were associated with them.
Furthermore, we will conduct an analysis of measurement error, which will help us determine why people were erroneously listed in the census and the Accuracy and Coverage Evaluation.
Many evaluations in this category that were planned for the A.C.E. were no longer need when the decision was made not to adjust the Census 2000 population counts.
It was determined that some of the reports that were developed in an expedited manner to inform the Executive Steering Committee for A.C.E. (ESCAP) decisions were sufficiently complete and informative to answer research questions from the planned evaluation reports.
Ten of these reports and their corresponding ESCAP reports are noted in the following section of evaluation report descriptions.
To review the ESCAP reports on the Internet, go to http://www.census.gov/ and search on "ESCAP."
May 2002
C-87 Coverage Evaluations of the Census and of the A.C.E. (O.1) Type of Enumeration Area Summary (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.2) Coverage of Housing Units in the Early Decennial Master Address File (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.3) Census 2000 Housing Unit Coverage Study This evaluation assesses 1) the net coverage rate of housing units, 2) the gross omission rate of housing units, and 3) the erroneous enumeration rate of housing units.
These assessments are made at the national level, smaller geographic levels, and for each post-strata.
This evaluation also examines the potential impact on housing unit coverage had we excluded specific Master Address File building operations.
This study is similar to the Housing Unit Coverage Study conducted in 1990.
It also has a corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation.
Refer to the ESCAP II report, "Census 2000 Housing Unit Coverage Study" (report 17).
(O.4) Analysis of Conflicting Households During A.C.E. housing unit matching, situations were found where the census and A.C.E. listed two entirely different families.
This study will document the follow-up interviewing results for these households to determine if the census was in error, the A.C.E. was in error, if the two families both live at the address, if there was misdelivery of the census form, and so on.
(O.5) Analysis of Proxy Data in the A.C.E.
Both the census and A.C.E. sometimes must collect data from proxy respondents--persons who are not members of the household where data are needed.
This study will examine match rates and erroneous enumeration rates for such cases in the A.C.E. (O.6) P-Sample Nonmatches Analysis (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "P-sample Nonmatch Analysis" (report 18).
Additionally, "Consistency of Census 2000 Post Stratification Variables," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(O.7) Analysis of Person Coverage in Puerto Rico (cancelled) May 2002
C-88 This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.8) Analysis of Housing Unit Coverage in Puerto Rico (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.9) Geocoding Error Analysis (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II reports, "E-sample Erroneous Enumeration Analysis" (report 5) and "Analysis of Nonmatches and Erroneous Enumerations Using Logistic Regression" (report 12).
(O.10) Housing Unit Duplication in Census 2000 Duplication in the census was one type of erroneous enumeration.
This analysis will identify duplicate housing units in Census 2000 and their characteristics.
The study will also determine if duplication was more likely for one group or another (e.g., owners vs. renters).
The census operations most likely to produce housing unit duplication will be identified, along with the most plausible sources of duplication.
(O.11) E-Sample Erroneous Enumeration Analysis (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation that is relevant to this evaluation.
Refer to the ESCAP II report, "E-Sample Erroneous Enumeration Analysis" (report 5).
Additionally, "Census 2000 E-Sample Erroneous Enumerations," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(O.12) Analysis of Nonmatches and Erroneous Enumerations Using Logistic Regression (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Logistic Regression" (report 19).
Additionally, "Modeling A.C.E.
Non-matches in the Census 2000," provides preliminary research findings that were presented at the 2001 American Statistical Association Conference.
For a copy of the paper, contact the Census Bureau on (301) 457-4218.
(O.13) Analysis of Various Household Types and Long Form Variables This study combines the housing unit data and the person data to study coverage.
A new link between A.C.E. housing units and census housing units in the sample will be created in the combined data based on the person matching result.
Then the combined data will be used to
May 2002
C-89 examine whether coverages are affected by variables such as address style, income, education, property value or rent, type of family, and household complexity.
(O.14) Measurement Error Reinterview Analysis (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II reports, "Evaluation Results for Changes in A.C.E. Enumeration Status" (report 3) and "Followup Review" (report 24).
(O.15) Impact of Housing Unit Coverage on Person Coverage Analysis This evaluation will not be conducted because the available data cannot answer the specified questions for this study.
(O.16) Person Duplication in Census 2000 People were duplicated in the census for many different reasons.
This analysis will identify the number and characteristics of duplicate persons in Census 2000.
The study will also determine if duplication was more likely for one group or another (e.g., owners/renters).
The census operations most likely to cause duplication will be identified, along with the most plausible sources of the duplication.
(O.17) Analysis of Households Removed Because Everyone in the Household is Under 16 Years of Age (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.18) Synthesis of What We Know About Missed Census People (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(O.19) Analysis of Deleted and Added Housing Units In Census 2000 Measured by the Accuracy and Coverage Evaluation The goal of this study is to assess the completeness of housing unit coverage on the early Decennial Master Address File (DMAF).
We will determine which census operations contributed to undercoverage by deleting units that should have not been deleted, and which operations improved coverage by adding units not previously accounted for.
We also will identify which census operations reduced housing unit duplication (O.20) Consistency of Census Estimates with Demographic Benchmarks This study uses independent demographic benchmarks to evaluate the accuracy of the Census 2000 counts and the completeness of coverage in Census 2000.
While this approach cannot produce estimates for as many demographic groups and geographic areas as A.C.E., results can be compared to A.C.E. at aggregate levels.
May 2002
C-90 (O.21) Implications of Net Census Undercount on Demographic Measures and Program Uses (cancelled) This evaluation will not be conducted.
It was cancelled before February 2001.
(O.22) Evaluation of Housing Units Coded as Erroneous Enumerations (cancelled) This evaluation, which was added after February 2001, will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Evaluation of Lack of Balance and Geographic Errors Affecting A.C.E.
Person Estimates" (report 2).
(O.23) Analysis of Insufficient Information for Matching and Followup (cancelled) This evaluation, which was added after February 2001, will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "E-Sample Erroneous Enumeration Analysis" (report 5).
(O.24) Evaluation of Lack of Balance and Geographic Errors Affecting Person Estimates (cancelled) This evaluation, which was added after February 2001, will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Evaluation of Lack of Balance and Geographic Errors Affecting A.C.E.
Person Estimates" (report 2).
(O.25) Mover Analysis (cancelled) This evaluation, which was added after February 2001, will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation II (ESCAP II) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Analysis of Movers" (report 15).
(O.26) Analysis of Balancing in the Targeted Extended Search (cancelled) This evaluation, which was added after February 2001, will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP I report, "A.C.E.
Data and Analysis to Inform the ESCAP Report" ( report B-1).
May 2002
C-91 P. Accuracy and Coverage Evaluation Survey Statistical Design and Estimation Overview The evaluations in this category were designed to examine the quality of Accuracy and Coverage Evaluation (A.C.E.) estimates.
Because of resource reallocation and Executive Steering Committee for Accuracy and Coverage Evaluation (ESCAP) analyses and documentation that informs evaluations, the evaluations for this category were not conducted.
Refer to specific evaluations for more information.
Some of the reports that were developed in an expedited manner to inform ESCAP decisions were sufficiently complete and informative to answer research questions from the planned evaluation reports.
Two of these reports and their corresponding ESCAP reports are noted in the following section of evaluation report descriptions.
To review the ESCAP reports on the Internet, go to http://www.census.gov/ and search on "ESCAP."
A.C.E.
Survey Statistical Design and Estimation Evaluations
May 2002
C-92 (P.1) Measurement of Bias and Uncertainty Associated With Application of the Missing Data Procedures (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation (ESCAP) analysis and documentation is relevant to this evaluation.
Refer to the ESCAP II report, "Analysis of Missing Data Alternatives for the A.C.E" (report 12).
(P.2) Synthetic Design Research/Correlation Bias (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
(P.3) Variance of Dual System Estimates and Adjustment Factors (cancelled) This evaluation will not be conducted.
A corresponding Executive Steering Committee for Accuracy and Coverage Evaluation I (ESCAP I) analysis and documentation that is relevant to this evaluation.
Refer to the ESCAP I report, "A.C.E.: Variance Estimates by Size of Geographic Area" ( report B-11).
(P.4) Overall Measures of A.C.E.
Quality (cancelled) This evaluation will not be conducted.
A summary report of various quality measures was previously planned.
However, this information will be included in a topic report assessing key findings for all A.C.E. evaluations.
(P.5) Total Error Analysis (cancelled) This evaluation will not be conducted.
In early 2002, the Census 2000 Evaluation Program was refined and priorities reassessed due to resource constraints at the Census Bureau.
May 2002
C-93 Q: Organization, Budget, and Management Information System Overview Research in this category will document headquarters decision making processes and the impact of headquarters organizational structure on the decennial census.
We plan to study the management approach, structure, processes, and management tools.
What Will We Learn? The findings from this study will help the Census Bureau to better manage future censuses and similar projects.
This study will document how well the Management Information System worked in helping us manage Census 2000.
We will compare the activities and recommendations of the Census 2000 research and development program to what was actually implemented for Census 2000 to determine which projects were most beneficial.
In addition, we will examine the roles and influences of both external and internal entities on planning and implementing the census.
Organization, Budget, and Management Information System Evaluation May 2002
C-94 (Q.1) Management Processes and Systems of the 2000 Decennial Census The purpose of this study is to evaluate the management model for Census 2000 including the organizational structure, the decision making process, and the management information tools.
The study will also assess the staffing, the use and management of contracts, and the impact of external influences such as the Census Monitoring Board, the Congress, the funding history, the General Accounting Office, and other stakeholders.
May 2002
C-95 R: Automation of Census Processes Overview For Census 2000, the Census Bureau implemented a series of automated systems to aid the conduct of the decennial census.
These systems included, but were not limited to, data collection and capture, cost and progress reporting, management controls, customer reaction, quality assurance and analysis, and the Internet.
Many of these systems were implemented for the first time in Census 2000.
There are a total of twelve systems that we will evaluate.
In general, we will assess whether the correct requirements and proper functionality were specified for each of these twelve systems, whether the systems performed adequately in terms of either impact on data quality or in providing useful management information, and whether we specified our requirements in a timely manner.
We also will examine any contract management issues, as applicable.
The twelve systems to be evaluated are as follows: Telephone Questionnaire Assistance; Coverage Edit Followup; Internet Questionnaire Assistance; Internet Data Collection; Operations Control System 2000; Laptop Computers for the Accuracy and Coverage Evaluation; Accuracy and Coverage Evaluation 2000 Control System; Matching and Review Coding System for the Accuracy and Coverage Evaluation; Pre-Appointment Management System/Automated Decennial Administrative Management System; American FactFinder; Management Information System 2000; and Census 2000 Data Capture.
What Will We Learn? Evaluation reports will be generated using information collected from debriefings with program managers, systems users, and others affiliated with the systems.
Questionnaires will be developed for each system that will address general issues concerning the system's functionality and the correct and timely specification of its requirements along with questions that are unique to each system.
We expect to gain insight, as appropriate, in areas such as maintenance and security needs, respondent acceptance, initial investment required, ease/difficulty of setup, reliability, level of training required, effects on coverage and response rates, additional costs or savings, and technology life cycle issues.
Automation of Census Processes Evaluations May 2002
C-96 A list of key questions to be answered for each system follows.
Â· Â· Â· Â· Did we specify the right requirements and functionality? Did the system do what we needed it to in terms of either its impact on data quality or in providing useful management information? Did we define our requirements in a timely manner? If a contractor was hired to work on the system, did the contractor effectively complete the required tasks?
(R.1.a) Telephone Questionnaire Assistance Telephone questionnaire assistance (TQA) was a toll-free service provided by a commercial phone center to answer questions about Census 2000 or the census questionnaire.
This system also included a reverse-CATI (computer-assisted telephone interview) operation.
For Census 2000, TQA was operated out of 22 phone centers nationwide from March through June 2000.
(R.1.b) Coverage Edit Followup Coverage Edit Followup (CEFU) was an outbound service operating out of 13 call centers to resolve count discrepancies (coverage edit failures) and to obtain missing information for large households.
The CEFU was conducted from May to August 2000.
(R.1.c) Internet Questionnaire Assistance Internet questionnaire assistance (IQA) was an operation that allowed respondents to use the Census Bureau's Internet site to ask questions and receive answers about the census questionnaire, job opportunities, or general questions about the purpose of the census.
This service was operative from March through June 2000.
(R.1.d) Internet Data Collection From March through April 2000, respondents to the Census 2000 short form had the option of completing their census form electronically by accessing the Census Bureau's Internet site and providing a 22-digit ID number found on their form received in the mail.
(R.2.a) Operations Control System 2000 The Operations Control System (OCS) 2000 was a decennial field interface system and was used for control, tracking, and progress reporting for all field operations conducted for the census, including production of materials used by field staff to do their work.
This system was operative from October 1997 through October 2000 for the pre-census and decennial operational phases.
May 2002
C-97 (R.2.b) Laptop Computers for Accuracy and Coverage Evaluation The Accuracy and Coverage Evaluation was a coverage measurement methodology that was used to determine the number of people and housing units missed or counted more than once in Census 2000.
The laptop computers were used to conduct personal and telephone interviews.
This evaluation examines and assesses the use of laptop computers in determining coverage error.
(R.2.c) Accuracy and Coverage Evaluation 2000 Control System The Accuracy and Coverage Evaluation 2000 Control System was a decennial system to aid management in tracking and controlling the Accuracy and Coverage Evaluation field operations.
(R.2.d) Matching and Review Coding System for the Accuracy and Coverage Evaluation The Matching and Review Coding System for the Accuracy and Coverage Evaluation was also referred to as the Accuracy and Coverage Evaluation survey matching system.
The system provided for a computer matching of housing units and persons followed by a clerical review of unmatched records.
This system was used at the Census Bureau's National Processing Center in Jeffersonville, IN.
(R.3.a) Pre-Appointment Management System/Automated Decennial Administrative Management System The Pre-Appointment Management System/Automated Decennial Administrative Management System was an integrated structure of administrative management programs that support applicant tracking and processing, background checks, selection records, recruiting reports, personnel and payroll processing, and archiving of historical data.
This system was used in the hiring of temporary workers for the census.
(R.3.b) American FactFinder The American FactFinder is a generalized electronic system for access and dissemination of Census Bureau data.
The system is available through the Internet and offers prepackaged data products and the ability to build custom products.
The system will serve as the vehicle for accessing and disseminating data from Census 2000 (as well as the 1997 Economic Censuses and the American Community Survey).
The system was formerly known as the Data Access and Dissemination System.
Census 2000 data products will be available through the American FactFinder began in January 2001.
(R.3.c) Management Information System 2000 The Management Information System (MIS) provides decision support functions, such as, critical-path analysis and what-if analysis.
It also provides information on dates, the responsible organization, budget, cost to date, and current progress of Census 2000 operations.
The MIS includes the master activity schedule, the executive information system, and the cost and progress system.
Designed as a tool for Census 2000, the MIS has an ongoing function.
(R.3.d) Census 2000 Data Capture
May 2002
C-98 The data capture process is a full electronic data capture and processing system for imaging Census 2000 questionnaires.
This process involves: 1) the check-in of paper forms; 2) the scanning and imaging of those forms; and 3) the use of optical mark and optical character recognitions to capture data from census questionnaire images that convert it to a computer readable format.
The Census Bureau worked with private sector companies to operate four data capture centers that were operative from March through October 2000.
May 2002
